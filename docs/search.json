[
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Documentation for ARC",
    "section": "Welcome",
    "text": "Welcome\nThis web book is a collection of general documentation, demostrations, and other supporting materials for John Curtin’s Addiction Research Center."
  },
  {
    "objectID": "lab_practices.html#general-information",
    "href": "lab_practices.html#general-information",
    "title": "1  Lab Practices",
    "section": "1.1 General Information",
    "text": "1.1 General Information\n\n1.1.1 Lab Information\n\n1.1.1.1 Building Address:\n1202 W Johnson St, Madison WI 53706\nThe lab Mailbox is on the 2nd floor, around the corner from Gary’s office facing the department head’s office (labeled Curtin/Wanta). Grads will be assigned their own mailboxes.\nOffices:\nJohn - 326\nGrad office - 325\nSusan - 187\nAriela - 191\nRA offices - 195, 192\nMost lab meetings are held in 228 or 311.\nKeys:\nSee Gary on 2nd floor for Lab and Building keys. Undergraduates will have to pay a $20 fee which will be refunded upon return of the keys. Let Susan know if you take this route and I’ll email him authorization.\nIn addition to the building key, you can request:\n30 key – first floor.\n9 key – grad office.\nFirst floor key box code: See Susan.\n\n\n1.1.1.2 Important Websites:\n\nLab website - http://arc.psych.wisc.edu\n\nLab Documentation - https://jjcurtin.github.io/docs_arc/\n\nLab Tidyverse Documention - https://jjcurtin.github.io/book_dwvt/\nJohn’s Introduction to Machine Learning Course- https://dionysus.psych.wisc.edu/iaml/\n\nRisk2 Project Manual - https://jjcurtin.github.io/docs_risk2/\n\n\n\n1.1.1.3 Productivity Software:\n\nOur lab uses Slack almost exclusively for internal communication (only occasionally email).\n\nWe use Asana for assigning & tracking tasks.\n\nWe maintain a lab reference manager database with Zotero.\nWe use Zoom for virtual meetings.\nWe use Qualtrics for our survey administration and management, including both participant surveys and surveys filled out by RAs.\nYou will need a Static IP so you can connect to our server remotely if you wish to use a personal computer for R, and/or wish to remote desktop into a lab computer. Please visit this page and request a Static IP. Provide the username (netid_1) and assigned IP address to Susan via email for her to authorize access in the firewall. After she confirms you are set, you will use GlobalProtect to enable mapping the drive, and/or Remote Desktop for accessing your work computer from off campus.\nWe use Office 365 for email, calendaring, etc. You can sign in with your wisc.edu account at email.wisc.edu, and either access the various Microsoft tools online, or download them to your office computer for use as standalone apps.\n\nWe will send you Slack, Asana, and Zotero invites to your wisc.edu email address, which you can use to create an account and access our lab resources.\nQualtrics and Zoom are UW-authorized software and you should sign up for them with your wisc.edu email through the links provided in the Campus Software Library. Let us know when done so we can add you to our various lab services.\n\n\n1.1.1.4 Data Analysis Software:\n\nWe use R and RStudio for data manipulation & analysis. They can be downloaded onto your personal computer, if you wish, or you can simply plan to use a lab computer. If you do download them yourself, remember you need to install R as a standalone prior to installing RStudio.\nWe store data analysis and manuscript code in repositories on Github. We also use Github Desktop to interface with those repos.\nWe use Quarto in R for writing grants, manuscripts, and data analysis scripts and documentation\nWe perform machine learning Data Analysis at the Center for High Throughput Computing (CHTC)\nWe use Ron’s Data Edit to view or edit csv data files outside of R. You will need to get the activation license from Susan.\n\nExcel is NOT appropriate to use with csv data files, as it imposes its own date formatting which then makes the data unreadable by R.\n\n\nYou should create user accounts on Github and CHTC and let us know so we can add you to the lab resources."
  },
  {
    "objectID": "lab_practices.html#lab-communications",
    "href": "lab_practices.html#lab-communications",
    "title": "1  Lab Practices",
    "section": "1.2 Lab Communications",
    "text": "1.2 Lab Communications\nThe Problem:  Asynchronous communication tools (Slack, email) are distracting, which can prevent deep work. Constant task switching interferes with complex tasks like writing and coding. These tools draw our attention and reduce our focus even when we are not checking them, simply by knowing that others may be trying to reach us with them.\nThese asynchronous communication tools may also be making us miserable. In the short-term, it is rewarding to respond to a simple request or add a cute emojii for feedback. However, it is frustrating to try to continuously monitor multiple communication channels through the day, every day.\nHowever, these tools were developed for a reason. We do need to communicate regularly because we are pursuing collaborative research aims. We need a better way to communicate that is efficient but not distracting.\nOur solutions are outlined below:\n\n1.2.1 Office hours\nWe will each hold office hours every day from 8:30 - 9:30 am. Students who have class or practicum conflicts are excused from office hours on those days. Otherwise, we should all plan to be available to each other during these hours.\nThese office hours allow us to communicate flexibly, individually or in groups, as needed. This way we will each have access to each other every day, though it is not expected that we will actually meet during these office hours every day.\nMeetings will happen as needed by a Zoom video or audio call. We can also call others to the meeting if necessary. Meetings can be very short (a few minutes) or longer (up to 30 minutes?) Do not plan to use the full hour as that will prevent others from communicating with this person. Long meetings, if needed, can be scheduled outside of office hours.\nWe will use the meetings-office-hours channel in Slack each morning before or at the start of Office hours to organize meetings during that time. If you need someone, its a good idea to give them a heads up by indicating that in the thread for the day. I will try to post something by the start of each office hour about my needs and inviting others to reserve time with me.\nEach of us should also use our office hours each morning to handle asynchronous communications (e.g., responding to email, Slack, Asana messages/tasks).\n\n\n1.2.2 Asynchronous or unscheduled communications\nWe will not remove all asynchronous communications. They can be efficient for some communication tasks. Urgent needs for communication can also arise unexpectedly. We need methods for these communications. They are as follows:\n\nSlack messages. Most asynchronous communications will continue to occur in Slack. Slack messages should be limited to questions or posts that do not require more than a single response from one individual. Examples include:\n\nPosts about articles to read, new analysis methods, etc to channels like software-r, read-papers, read-media. These posts do not require any response but many of us (myself included) find them valuable to read at moments when we are not doing deep work.\nQuestions directed at as single lab member requesting clear information that will not (likely) require follow-up or clarification (i.e., a series of back-and-forth messages over a short period). We should @ the person within the appropriate channel or DM them. They will respond the next morning during their office hours.\n\nTask assignments in Asana. If we need someone to DO something, don’t use Slack. Asana was designed to track tasks and it does this well. Assign that person a task directly in Asana. Set a due date for when you need it (they can adjust this date if necessary to accommodate their own schedule). Describe the task fully in the description box. If the task requires discussion, discuss it with them during that person’s office hours. Do NOT engage in a series of back and forth messages in Asana! Live meetings are appropriate for discussions. Some messages or update can be posted in Asana. Expect these messages to be read the next day during the person’s office hours. Use @ to make sure the person sees your message (comment)\nPhone calls for urgent communications. Urgent communications may be necessary at times. If you need information from someone immediately, call them. This will allow us to be available for urgent issues without having to monitor some communication channel. However, we should very carefully consider how urgent our need is. We recognize that we are likely disrupting someone else’s deep work. This cost to them should be recognized. Most issues can wait until the next morning.\nLab notebooks for documentation. Slack and Asana were not designed for documentation. For documentation, we will begin to make heavier use of lab notebooks maintained through Quarto. At this point these will include:\n\nProject manuals - for procedure and materials for a grant funded or other parent project.\nProject progess reports - for updates and meeting notes about those projects.\nStudy notebooks - for notes about analyses for specific papers.\n\nGithub and coding tasks. We will continue to use issues in Github to document coding needs for specific projects, studies, and lab toolboxes. At this point, we don’t yet have a clear integration of Github issues with Asana tasks. This is something we still need to address.\n\n\n\n1.2.3 Professional Calendaring\nWe all need to commit to keep our Outlook calendar up to date with all meetings and planned absences during business hours in the work week. This will allow each of us to view others calendars and use Outlook’s scheduler to find times that are available for all of us. This anticipates that the whole university is pushing to establish Outlook as our “business” calendar. As adoption increases, this will remove the need for time consuming schedule poll (e.g., whentomeet) for all of us. I understand that many of you may use other calendars for your personal use. However, Outlook will be the official work calendar. If you use other calendaring systems, please make sure that you have shared events in that calendar such that the are viewable (public or private by your choice) in Outlook.\nWe may send invites to share Google calendars with you if you are assigned to work on a study with a calendar. These calendars are used to view scheduled sessions for studies.\n\n\n1.2.4 Intro to Slack\nOur Slack workspace is the primary place that lab members communicate with each other (preferable to email) as it allows everyone to keep informed about study and project activities or decisions.\n\nJohn creates channels. You are welcome to browse and subscribe to as many channels as interest you!\n\nProj-name: These are channels for specific projects which are overarching research programs, mostly linked to an R01 or other Grant, or Dissertation\nStudy-name: Each Project can result in several studies which are analyses of specific subsets of project data; these are channels for Studies.\n\nInside Channels we can post Threads. Each Thread is a semi or fully self-contained topic or conversation related to the channel.\n\nWhen replying to a thread, be sure to reply in the thread and not as a new thread in the channel.\nAs much as possible, try to keep related questions together in a single thread, as this allows for better tracking of decisions and milestones related to that topic.\n\nWe also use DMs (direct messages) for conversations that are more ephemeral or don’t require group discussions.\n\nDMs don’t always use threaded conversations as heavily, depending on the preferences of the people in it. For example, I often still use threaded conversations in DMs with John, but not with other staff.\nYou will need to have a separate conversation with any permutation of people. For example, if you and John are having a DM conversation and wish to loop me in, Slack will start a new conversation, and I will not be able to view anything that was previously posted in that conversation.\n\n\n\n1.2.4.1 Slack Best Practices:\n\nIn most* cases, Slack is NOT meant for “immediate” communication. You are not expected to reply immediately, but should be checking and responding to messages during office hours as outlined above.\n\nIf you need John for an immediate question, call him instead of sending a Slack message.\n*If you need Susan for an immediate question, you are free to DM in Slack! I am always available and it’s the fastest way to get in touch with me.\n\nWhen you wish to notify someone in a thread or a reply, you should tag them using the @ symbol. Otherwise they may not see it!\nWe use Reactions fairly heavily in the lab to indicate that we’ve received information/seen a reply or thread, if it doesn’t explicitly ask for a verbal response. For example, John may tell post a thread “I’ve just updated the repo, be sure to update from Github before you start working” – a thumbs up or checkmark reaction is an indicator to John that you’ve seen and taken the necessary action.\n\n\n\n\n1.2.5 Intro to Asana\nAsana is an online task-management system that we use to keep track of tasks and milestones. Graduate students are expected to use Asana to manage their First Year Projects.\n\nJohn will help you create Projects for each of your FYPs.\nYou or John can create Tasks in your project, and set up due dates or dependencies.\n\nLike Slack thread replies, you can have comments on an Asana task to ask for clarification or provide updates to the assignee/assigner.\n\nWhen working on a collaborative task, you can re-assign a task to someone else. For example while working on a task from John, you may assign it back to him for input or review, and he will assign it back when there is an action response for you."
  },
  {
    "objectID": "lab_practices.html#human-subjects-training",
    "href": "lab_practices.html#human-subjects-training",
    "title": "1  Lab Practices",
    "section": "1.3 Human Subjects Training",
    "text": "1.3 Human Subjects Training\nAll lab members are required to be up to date with the UW required human subjects training courses:\n\nHIPAA - visit https://compliance.wisc.edu/hipaa/training/ and click the Canvas link for the training.\nCITI go to https://apps.research.wisc.edu/citi and sign up for:\n\nUW Human Subjects Protections Course\nGCP – Social and Behavioral Research Best Practices for Clinical Research\nBasics of Effort Reporting (grad students only; NOT the one listed for the SMPH)\n\n\nThese trainings need to be renewed periodically. You will receive emails or notifications when renewal approaches."
  },
  {
    "objectID": "lab_practices.html#security-and-privacy",
    "href": "lab_practices.html#security-and-privacy",
    "title": "1  Lab Practices",
    "section": "1.4 Security and Privacy",
    "text": "1.4 Security and Privacy\n\nAll lab members are expected to keep their workstations secure. It should be set to lock automatically after 5 minutes and you should be in the habit of locking your workstation whenever you leave your desk.\nDoor should be locked behind you when not in the room. Never leave a room unattended and open.\nFile cabinets should be locked when not in use. All files must be in locked cabinets when not in use.\nNEVER leave participant or financially related files out on your desk overnight. For brief periods away from your desk, make sure all information is covered or secured.\nNever share keys, passwords, or other information except those which are explicitly provided to you as being for multi-user access.\nAll lab members are expected to respect the privacy of participants by keeping conversations, files, and other items private per the Confidentiality Agreement and per the Participant Privacy section below.\nA copy of the Confidentiality Agreement must be signed by each lab member, their mentor/supervisor, and filed by the Lab Manager\n\n\n1.4.1 Using Lab Computers\n\nNever save anything to a computer locally (meaning do not save items to a computer’s desktop or C drive) unless it is 100% reproducible and okay to immediately be lost forever (e.g. scratch documents for your use only)\nStudy data should be saved in the designated location on the shared P drive for that study.\nPersonal information should not be saved to the shared P drive OR a local computer.\n\nIf you do save personal information to a computer, that information is in jeopardy or being lost.\nInstead of saving to the computer, it is recommended that you save your personal information Google drive, UW Box, or Github, all of which are available from anywhere you have internet.\n\nIf you are an undergraduate student, then you will need to log onto a computer using the log-in information provided to you by the study coordinator or your supervisor/mentor.\nIf you are not an undergraduate student, you will log into a computer using a personal log in name and password. This log-in name in and password will need to be set up by John or the lab manager.\n\n\n\n1.4.2 Participant Privacy\n\nAlways give participants as much privacy as is possible for answering questionnaires.\nNEVER speak about any past, present or future participant if you are within hearing range of anyone who does not work in our lab.\nNever discuss study participants with other study participants, even if a participant volunteers that they know another participant. Discuss with the lab manager or study coordinator if you have any concerns.\nAny papers or files with a participant’s personal information must be kept out of plain sight at all times.\nIf any papers with participant information need to be thrown out, be sure to shred it (the shredder is in room 187 or 192)."
  },
  {
    "objectID": "lab_practices.html#undergraduate-ra-expectations",
    "href": "lab_practices.html#undergraduate-ra-expectations",
    "title": "1  Lab Practices",
    "section": "1.5 Undergraduate RA Expectations",
    "text": "1.5 Undergraduate RA Expectations\n\nUndergraduate RAs are expected to work approximately 10 hours per week in the lab.\n\nTimesheets for paid students are approved by Susan and should be submitted through my.wisc.edu\nYou can request course credit (Psych 621) for up to 3 credit-hours in exchange for your participation.\n\nNOT all RAs are eligible for mentored research (ie, Bio 152 or a Senior Thesis). Please speak to Susan about requirements to be considered for this.\n\n\nWe will work with you to schedule your shifts at times that don’t interfere with your classes/extracurricular activities.\n\nIf you are scheduled for a participant visit and it is cancelled, you are still expected to be present in the lab at that time and use the time for training or other duties, unless told otherwise.\nAlthough we are very flexible with respect to exams, vacations, etc; you MUST let us know in advance if you will be absent for a scheduled participant visit/session.\n\nWe communicate primarily by Slack and request that you are prompt in responding to direct messages or mentions (during your shift, please try to reply immediately unless you are with a participant; outside your shift, please reply within 24 hours excepting weekends).\n\nWe also do communicate intermittently by email. You may wish to read this primer on workplace email etiquette if you are not already very familiar with how employers use email: https://www.thebalancecareers.com/email-etiquette-525535\nAll lab members (excluding RAs) hold office hours daily from 8:45 am – 9:45 am, during which time we are available for meetings by request. RAs are not required to hold office hours although you are welcome to send a slack message to anyone to request a meeting during this time.\nIf you have questions, Susan is reachable via slack pretty much all the time!\n\nDress code: Outside of face-to-face participant interaction, there is no dress code.\n\nWe currently (2023) do not have in-person participant visits; but if we did, the dress code for those would be light business casual (No sweats, shorts, or sneakers, no t-shirts with logos or text, no tank tops or cropped tops). You will often be dealing with a community population and are expected to present yourself professionally as a representative of the lab and the University."
  },
  {
    "objectID": "grad_expectations.html#lab-communications",
    "href": "grad_expectations.html#lab-communications",
    "title": "2  Graduate Student/Mentor Expectations/Policies",
    "section": "2.1 Lab Communications",
    "text": "2.1 Lab Communications\nAsynchronous communication tools (Slack, email) are distracting, which can prevent deep work. Constant task switching interferes with complex tasks like writing and coding. These tools draw our attention and reduce our focus even when we are not checking them, simply by knowing that others may be trying to reach us with them. These asynchronous communication tools may also be making us miserable. In the short-term, it is rewarding to respond to a simple request or add a cute emojii for feedback. However, it is frustrating to try to continuously monitor multiple communication channels through the day, every day.\nHowever, these tools were developed for a reason. We do need to communicate regularly because we are pursuing collaborative research aims. We need a better way to communicate that is efficient but not distracting. We have a hybrid approach:\n\n2.1.1 Office hours\nWe will each hold office hours every day from 8:30 - 9:30 am. Students who have class or practicum conflicts are excused from office hours on those days. Otherwise, we should all plan to be available to each other during these hours. This way we will each have access to each other every day, though it is not expected that we will actually meet during these office hours every day.\nIf you need someone, its a good idea to give them a heads up by indicating that in a slack message earlier that morning or the previous afternoon. You can initiate communication during office hours either in slack or by phone (or across the desks if you are on campus!). You might consider a zoom if you need to bring in multiple people in different locations.\nMeetings can be very short (a few minutes) or longer (up to 30 minutes?) Do not plan to use the full hour as that will prevent others from communicating with this person. Long meetings, if needed, can be scheduled outside of office hours.\nEach of us will also use our office hours each morning to handle asynchronous communications (e.g., email, Slack, Asana messages/tasks).\n\n\n2.1.2 Asynchronous or unscheduled communications\nWe will not remove all asynchronous communications. They can be efficient for some communication tasks. Urgent needs for communication can also arise unexpectedly. We need methods for these communications. They are as follows:\n\nSlack messages. Most asynchronous communications will continue to occur in Slack. Slack messages should be limited to questions or posts that do not require more than one (or two?) responses from one individual. Examples include:\n\nPosts about articles to read, new analysis methods, etc to channels like software-r, read-papers, read-media. These posts do not require any response but many of us (myself included) find them valuable to read at moments when we are not doing deep work.\nQuestions directed at as single lab member requesting clear information that will not (likely) require follow-up or clarification (i.e., a series of back-and-forth messages over a short period). We should @ the person within the appropriate channel or DM them. They will respond the next morning during their office hours.\n\nTask assignments in Asana. If we need someone to DO something, don’t use Slack. Asana was designed to track tasks and it does this well. Assign that person a task directly in Asana. Set a due date for when you need it (they can adjust this date if necessary to accommodate their own schedule). Describe the task fully in the description box. If the task requires discussion, discuss it with them during office hours. Do NOT engage in a series of back and forth messages in Asana! Live meetings are appropriate for discussions. Some messages or update can be posted in Asana. Expect these messages to be read the next day during the person’s office hours. Use @ to make sure the person sees your message (comment)\nPhone calls for urgent communications. Urgent communications may be necessary at times. If you need information from someone immediately, call them. This will allow us to be available for urgent issues without having to monitor some communication channel. However, we should very carefully consider how urgent our need is. We recognize that we are likely disrupting someone else’s deep work. This cost to them should be recognized. Most issues can wait until the next morning.\nLab notebooks for documentation. Slack and Asana were not designed for documentation. For documentation, we will begin to make heavier use of lab notebooks maintained through Quarto. There is a strong expectation that we are all contributing to these various documentation efforts. Its simply too much to be maintained solely by John and Susan. At this point these notebooks will include:\n\nProject manuals - for procedure and materials for a grant funded or other parent project. These manuals can also include units on data cleaning, design, hypotheses, etc. These repos are public and called docs_PROJECTNAME. We currently have\n\ndocs_risk\ndocs_risk2\ndocs_face\n\nARC documentation (docs_arc) - A documentation notebook for our lab about general lab issues\nDWT (dwt) - A web book documenting best practices for data wrangling and visualization using the tidyverse.\n\n\n\n\n2.1.3 Professional Calendaring\nWe all need to commit to keep our Outlook calendar up to date with all meetings and planned absences during business hours in the work week. This will allow each of us to view others calendars and use Outlook’s scheduler to find times that are available for all of us. This anticipates that the whole university is pushing to establish Outlook as our “business” calendar. As adoption increases, this will remove the need for time consuming schedule poll (e.g., whentomeet) for all of us. I understand that many of you may use other calendars for your personal use. However, Outlook will be the official work calendar. If you use other calendaring systems, please make sure that you have shared events in that calendar such that the are viewable (public or private by your choice) in Outlook.\nWe may send invites to share Google calendars with you if you are assigned to work on a study with a calendar. These calendars are used to view scheduled sessions for studies."
  },
  {
    "objectID": "grad_expectations.html#weekly-lab-meeting",
    "href": "grad_expectations.html#weekly-lab-meeting",
    "title": "2  Graduate Student/Mentor Expectations/Policies",
    "section": "2.2 Weekly Lab Meeting",
    "text": "2.2 Weekly Lab Meeting\n\nhappen weekly\neveryone is expected to contribute to selecting topics\neveryone is expected to lead some meetings\npost topics and materials by Friday (at the latest) for the next week\nLocation TBD. Outside when possible/pleasant"
  },
  {
    "objectID": "grad_expectations.html#weekly-studentmentor-meeting",
    "href": "grad_expectations.html#weekly-studentmentor-meeting",
    "title": "2  Graduate Student/Mentor Expectations/Policies",
    "section": "2.3 Weekly Student/Mentor Meeting",
    "text": "2.3 Weekly Student/Mentor Meeting"
  },
  {
    "objectID": "grad_expectations.html#research-contributions-in-the-lab",
    "href": "grad_expectations.html#research-contributions-in-the-lab",
    "title": "2  Graduate Student/Mentor Expectations/Policies",
    "section": "2.4 Research Contributions in the Lab",
    "text": "2.4 Research Contributions in the Lab\n\nEveryone makes contributions to lab projects\nThese activities provide:\n\nImportant training activities\nKeeps us connected to how the data are collected and cleaned, which is important when we write papers\nServes to create data that are used by current and future students (and past students did the same for you!)\n\nThe nature of the contributions often change based on developmental stage and skill set\n\nYounger students more often may collect data and/or meet with participants\nOlder students may do more EDA or data management\n\nStudents who are supported as RAs or on university or training fellowship (e.g., Emotion training grant) are expected that to use their hours (up to 20 depending on support) dedicated to a lab project.\nStudents who are NRSA supported are expected to work primarily on the aims of that associated grant\nStudents who are supporting themselves through teaching will also make contributions but with likely many fewer hours given the demands of their TA\nJohn will negotiate these assignments each semester as part of discussing your funding"
  },
  {
    "objectID": "grad_expectations.html#mentoring-and-studypaper-collaborations",
    "href": "grad_expectations.html#mentoring-and-studypaper-collaborations",
    "title": "2  Graduate Student/Mentor Expectations/Policies",
    "section": "2.5 Mentoring and Study/Paper Collaborations",
    "text": "2.5 Mentoring and Study/Paper Collaborations\nIdeas under development. Likely involves more advanced students collaborating as secondary mentors on FYPs. May also involve first year students collaborating on studies led but more advanced students."
  },
  {
    "objectID": "grad_expectations.html#authorship-expectations",
    "href": "grad_expectations.html#authorship-expectations",
    "title": "2  Graduate Student/Mentor Expectations/Policies",
    "section": "2.6 Authorship expectations",
    "text": "2.6 Authorship expectations\nGraduate students will be first authors on their FYP and dissertations in almost all instances. However, if the student is unable to make progress a published version of their project for an extended period of time and the only way to motivate another student to complete that project is by providing them with first author credit, the authorship order could be changes. In those instances, the graduate student would still remain a co-author. Such authorship reordering would only happen following numerous conversations with John about failure to make progress.\nGraduate students will be first authors on independent projects that they design with me and lead as part of their larger program of research. However, as with FYP and dissertations, the authorship order could be changed if progress stalled for an extended period of time. The bar for re-ordering may be somewhat lower for this type of project than for an FYP/Dissertation. As with FYP/Dissertation, such re-ordering would only happen following numerous discussions about progress concerns.\nGraduate students who work as RA/project coordinator on large (i.e., multi-year) R01s (e.g. NRT1, RISK, DOX) should not assume that they will be the first author of all projects published from that grant except in very exceptional circumstances (e.g., the grant includes a sizable intellectual AND practical contribution from the student). If the graduate student takes a part of the grant as an FYP/Dissertation, expectations about author follow as described above. However, there will often be multiple supplemental papers that emerge from an R01 including papers addressing its specific aims and other papers that emerge as the project unfolds. As these supplemental papers are identified, John will offer them to specific students. In these instances, John follows these general guiding principles:\n\nIs the paper within the student’s current or desired program of research?\nDoes the student have the skill set to lead the project (or is this a skill set they want and John can support them developing)?\nDoes the student have the time to make reasonable progress on the project?\nWill the project help advance or otherwise support the student’s professional development?\nHas the student make substantial contributions to the lab outside of their own projects (e.g., mentoring; infrastructure development; programming; grant writing)?\n\nJohn will make these preliminary decisions about first author assignment on supplemental papers transparent (i.e., John will share with grads when such assignments have been established). This will allow an opportunity for others to negotiate with John if they disagree with the decision.\nThese first author assignments on supplemental papers is preliminary. It is not sufficient to simply express interest or otherwise claim a project to guarantee the first author role on these projects. Authorship order is first established definitively when progress on the project is meaningfully initiated. Prior to that, the bar to re-offer the project to someone else is relatively low (and likely based on some combination of how much times passes since the project is preliminarily assigned, how motivated John is to get the paper published, and who else is available to take the lead).\nDecisions about co-authors and order are negotiated by the first and the senior (John) authors. These decisions are made on a paper by paper basis after considering many factors (skill set of the first author, professional development goals/needs of other graduate students/staff/undergrads, scope/complexity of the project, etc). As noted below, the first author will document expectations of contributions from co-authors to allow some accountability as the project progresses.\nWhen projects/papers are first developed, an Asana project will be established for the paper. The student first author will be responsible for detailing initial expectations about authorship order, contributions, and timeline. This can be detailed in the studies unit in docs_arc. This information can be updated if expectations change over time. Preliminary assignments should be documented here too (by the student). However, as noted above, preliminary assignments are not finalized until meaningful initiated.\nAuthorship order changes will not happen without substantial previous discussion. However, they can happen if expectations about progress are not met. This is necessary to guarantee that our labs investment of time and resources results in published papers in a timely manner.\nWe will make every effort to include staff and exceptional undergrads (e.g., Hilldale fellows; Senior theses) as co-authors on papers that they make meaningful contributions. It is less likely that staff/undergrads will be first author on a project but this can happen in situations where grads are not interested or available to write papers in a timely fashion."
  },
  {
    "objectID": "grad_expectations.html#first-year-student-orientation",
    "href": "grad_expectations.html#first-year-student-orientation",
    "title": "2  Graduate Student/Mentor Expectations/Policies",
    "section": "2.7 First Year Student Orientation",
    "text": "2.7 First Year Student Orientation\nThe following two documents need to be reviewed and/or completed early in the semester.\n\nAll first year students should have a “First Year Fall Meeting” with their mentors. The mentor should be filling out the First Year Fall Meeting Form as the conversation progresses (this form must be completed by the mentor; you must be logged into the UW-Google Space). Basically it’s just a series of checkboxes that you check once you’ve talked about the given topic (e.g., topics related to the FYP, to coursework, to how the lab functions, etc.).\nAll first year students and their advisors should go over and discuss the (Advisor-Advisee Compact)[http://psych.wisc.edu/wp-content/uploads/2023/09/Advisor-AdviseeCompact_2023.pdf]. This is a pdf and there’s nothing to fill out/submit. It’s just part of a conversation you should have.\n\nIn addtion, once a Mentoring Committee has been established (i.e., all the faculty members have agreed to serve on the committee and the committee is finalized), the Established Mentoring Committee form should be completed by the student."
  },
  {
    "objectID": "studies.html#risk",
    "href": "studies.html#risk",
    "title": "3  Current and Planned Studies",
    "section": "3.1 RISK",
    "text": "3.1 RISK\n\nCompare insight only to full EMA for lapse risk prediction [Gaylen (lead), Kendra, Ariela, Sarah]\nGPS features solo for lapse risk prediction [Claire FYP (lead)]\nLess burdensome EMA for lapse risk prediction. Maybe only morning. Maybe only some items. Maybe only some items depending on responses to other items [Coco?]\nUse text message content & meta data for lapse prediction [Coco?]\nReplicate stressor use with RISK data. MLM analyses [unassigned]\nFull model using GPS, EMA, communications for lapse risk prediction [unassigned]\nLagged week level models for lapse risk prediction. Maybe 3 days, 1 week, two weeks lag [unassigned]\nModel duration of lapse rather than binary outcome to allow move toward harm reduction approaches\nModel lapses that are labeled (or quantified) on severity based on chaining, or perhaps the respone to them (what the say about future ab goal, EMA affect after, etc)\nEstablish individual lapse as a clinically meaningful event - use lapse/no lapse as feature to predict variety of negative outcomes from (next? subsequent period?) EMAs, e.g., craving, risky situations, stressful events, negative affect, self-efficacy/change of abstinence goal (abstinence violation effect). Account for previous negative outcome level (either include as covariate [feature]? or make outcome a change score) [unassigned]"
  },
  {
    "objectID": "studies.html#risk2",
    "href": "studies.html#risk2",
    "title": "3  Current and Planned Studies",
    "section": "3.2 RISK2",
    "text": "3.2 RISK2"
  },
  {
    "objectID": "studies.html#nrt1",
    "href": "studies.html#nrt1",
    "title": "3  Current and Planned Studies",
    "section": "3.3 NRT1",
    "text": "3.3 NRT1\n\nBuild machine learning model for smoking lapse risk prediction (e.g., replicate RISK ema paper) [unassigned]"
  },
  {
    "objectID": "studies.html#face",
    "href": "studies.html#face",
    "title": "3  Current and Planned Studies",
    "section": "3.4 FACE",
    "text": "3.4 FACE"
  },
  {
    "objectID": "resources.html#repositories",
    "href": "resources.html#repositories",
    "title": "4  Lab Resources",
    "section": "4.1 Repositories",
    "text": "4.1 Repositories\nA full list of John’s GitHub repos can be found here. A few frequently used ones:\n\nlab_supoort: Contains R functions, chtc code, and quarto templates written for specific ARC tasks.\narc_measures: Copies of our collected individual difference measures and their scoring code and related reference material. Any questionnaire which is copyrighted will only have our scoring file and a link to the copyright holder, if known."
  },
  {
    "objectID": "resources.html#quarto-templates",
    "href": "resources.html#quarto-templates",
    "title": "4  Lab Resources",
    "section": "4.2 Quarto Templates",
    "text": "4.2 Quarto Templates\nAll of the following templates are quarto files for use in creating lab-related documentation\n\nSimple Quarto Template. This simple template allows you to set margins/font and to switch from HTML to PDF output.\n\n\n4.2.1 YAML files\nIncluding these YAML files in a blank .qmd document sets up output for either HTML or PDF, tailored to ARC standards with respect to margins, font, etc.\nTBD (CONTENTS NEED TO BE ADDED TO THESE FILES)\n\nHTML YAML\nPD YAML\n\n\n\n4.2.2 Latex Support Files\nTBD\n\nincludes.tex - this file includes frequently used packages and their specifications. (Will expand)\ndefine_headers_arc.tex - define H1 - H3 headers per John’s specifications\ndefine_headers_apa.tex - define H1 - H5 headers per APA specifications\nnih_template.tex - contains formatting related to NIH grant writing including header and bibliography formatting.\n\n\n\n4.2.3 Manuscripts\n\n4.2.3.1 APA\n.qmd template. This is based on the template at this repo. Our version is currently under development to try and load assets from our lab_support repo rather than installing the extention files locally.\n\n\n4.2.3.2 CSL files\nBelow are the YAML code of a couple that we use frequently (linked to the primary CSL repo)\nNIH Grant Proposals:\ncsl: https://raw.githubusercontent.com/citation-style-language/styles/master/national-library-of-medicine-grant-proposals.csl\nElsevier (Vancouver substyle):\ncsl: https://raw.githubusercontent.com/citation-style-language/styles-distribution/f8524f9b9df60e94e98f824f242a1fb27cc9fc59/elsevier-vancouver.csl\nAPA 7th Edition:\ncsl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl\nNote: the apa quarto template in the lab_support repo calls its own version of the apa.csl from within its ex_apa support folder.\n\n\n\n4.2.4 Grants\nTBD\n\n\n4.2.5 Other\nLetterhead: .qmd template. See Susan or John for assistance in personalizing this for other lab members."
  },
  {
    "objectID": "quarto.html#assigning-values-to-parameters",
    "href": "quarto.html#assigning-values-to-parameters",
    "title": "5  Quarto",
    "section": "5.1 Assigning values to parameters",
    "text": "5.1 Assigning values to parameters\nYou define parameters in the YAML using the syntax below\n\nYou can assign initial values to the parameters. These values will be used by default if you do not replace them with new values from the command line when you render the script.\nYou can update these values with new values you pass in when you render the script (see below).\n\nIf you only provide a subset of updated parameter values when you render the document, the default values will be used for the remaining parameters.\n\n\nparams:\n  pv1: 5\n  pv2: 10\n\nFor a variety of reasons, I prefer to assign the values from the params list to individual variables\n\nCode is shorter when using these variables\nI can update them interactively if I want to use different values (the params list is read-only)\n\nFirst set the parameters in the YAML as above. Then put this code chunk right at the top of the script. If you edit this code chunk to assign new values interactively, make sure you comment it out when you save the final script!\n\npv1 &lt;- params$pv1\npv2 &lt;- params$pv2\n# pv1 &lt;- 5 # Use this line to interactively assign new value\n# pv2 &lt;- 10 # use this line to interactively assign new value"
  },
  {
    "objectID": "quarto.html#using-parameter-values",
    "href": "quarto.html#using-parameter-values",
    "title": "5  Quarto",
    "section": "5.2 Using parameter values",
    "text": "5.2 Using parameter values\nWhen you use params in the YAML, a list named params is created.\n\nYou can then use this list as normal with no further code needed to establish the values.\n\n\nparams$pv1 + params$pv2\n\n[1] 15\n\n\n\nYou can also access these values using inline r statements. See example below. I strongly recommend using this in the title of your document so that you can confirm that you correctly updated the parameter values when you rendered! e.g.,\n\n\ntitle: \"Demo of quarto document with pv1 = `r params$pv1` and  pv2 = `r params$pv2`.\"\n\n\nOr if you assigned the parameter values to variables as I recommended, you can just use those variables as you normally would. They will start with the values assigned to associated parameters (in YAML or input from command line)"
  },
  {
    "objectID": "quarto.html#passing-parameter-values-at-command-line",
    "href": "quarto.html#passing-parameter-values-at-command-line",
    "title": "5  Quarto",
    "section": "5.3 Passing parameter values at command line",
    "text": "5.3 Passing parameter values at command line\nI prefer to render quarto documents in the terminal.\n\nYou can indicate the output filename (otherwise, the output file name is set to the input filename with a different extension).\n\nYou can also pass in values to the parameters, which is typically why we use parameters in the first place\n\nUse the following syntax to render quarto documents at command line.\n\nuse -P to provide a parameter value. No space between parameter name and value. If you provide values for only a subset of parameters, defaults will be used for other parameters\nuse -o to specify filename (defaults to input filename if not provided).\n\n\nquarto render docname.qmd -o outputname.html  -P pv1:1 -P pv2:5\n\nFor rendering books and slides, we have written a bash script to handle setting the _quarto.yml file and then rendering the full project or a single file.\n\ncall the function from the terminal: ./render.sh filename.qmd book\nthe first parameter can be the name of the qmd file or all to render all units (only used for books, not slides)\nthe second parameter can be book, slides or slides_wide"
  },
  {
    "objectID": "chtc.html#chtc-office-hours-live-help",
    "href": "chtc.html#chtc-office-hours-live-help",
    "title": "6  CHTC",
    "section": "6.1 CHTC Office Hours & Live Help",
    "text": "6.1 CHTC Office Hours & Live Help\nSee the Get Help Page. Rachel and Christine are our two main support people at CHTC. You can email them at chtc@cs.wisc.edu\nThe zoom link for CHTC office hours is go.wisc.edu/chtc-officehours. Office hours are current scheduled at * Tuesday morning: 10:30am - 12:00pm * Thursday afternoon: 3:00 - 4:30 pm."
  },
  {
    "objectID": "chtc.html#logging-in",
    "href": "chtc.html#logging-in",
    "title": "6  CHTC",
    "section": "6.2 Logging In",
    "text": "6.2 Logging In\n\nOpen PuTTY. Enter Hostname: submit-1.chtc.wisc.edu, Port: 22, connection type: ssh\nLog in with your netid. You will have to use DUO for MFA.\nOpen WinSCP. Use the same credentials as PuTTY. You can drag files between your computer and CHTC. You can also edit documents with this program."
  },
  {
    "objectID": "chtc.html#hello-world-and-general-help",
    "href": "chtc.html#hello-world-and-general-help",
    "title": "6  CHTC",
    "section": "6.3 Hello World and General Help",
    "text": "6.3 Hello World and General Help\nFor substantial help, you can start with the CHTC home page and their list of how to docs for HTC.\nCHTC provides a Hello World overview of how to use CHTC. It is worth a review for new users."
  },
  {
    "objectID": "chtc.html#software",
    "href": "chtc.html#software",
    "title": "6  CHTC",
    "section": "6.4 Software",
    "text": "6.4 Software\nOn windows, use PuTTY for secure shell connection (SSH) to CHTC submit server and WinSCP for FTP."
  },
  {
    "objectID": "chtc.html#general-chtc-workflow",
    "href": "chtc.html#general-chtc-workflow",
    "title": "6  CHTC",
    "section": "6.5 General CHTC Workflow",
    "text": "6.5 General CHTC Workflow\n\n6.5.1 Making Batch of Jobs\n\nCreate or edit the training controls file for your batch of jobs. You should start with the demo training_controls.R file in the lab_support repo.\nRun (and create if necessary) mak_jobs.R for your study. To create it, start with the demo in the lab_support repo. You will need to update the path to your training controls file when creating the file.\nmake_jobs() is called by the mak_jobs.R script. It will make a new folder for your batch of jobs on the server in the chtc folder for your study.\nFTP all of the files in the input folder for this batch of jobs to the CHTC submit server.\n\n\n\n6.5.2 Testing Jobs\n\nMake sure you have a results folder and an error folder in your home directory.\nMake sure you have all files for the batch of jobs you will train (see above) and train.sif\nEdit job_nums.csv on CHTC server to contain some (e.g., 3) jobs with only several configs (e.g., 5) in each bin (job/row). For example, you can create the content below by typing printf \"1,1,5\\n2,6,10\\n3,11,15\" &gt; job_nums.csv\n\n1, 1, 5\n2, 6, 10\n3, 11, 15\n\nType condor_submit train.sub to submit this jobs\nMonitor the jobs using condor_q and -condor_q -hold if needed\nConfirm that there are data in the results file (file size &gt; 0 for all files): ls results/results* -lS. This will sort files with size = 0 to the bottom of the list. There should not be any!\nConfirm that the correct number of results files were created by counting them: ls results/results* | wc -l\nCheck for error files with error messages (file size &gt; 0): ls error/error* -lSr. This will sort the non-zero files to the bottom of the list.\n\nIf there are non-zero files, look at the error messages using nano editor: For example, nano error/error_1.err\nDetermine the run time for your test jobs: condor_history $USER -limit 3 (where limit is the number of test jobs you ran). You want to bin enough configurations together in a job to have it last for 2-3 hours. You may need to run mak_jobs.R again with a different value for configs_per_job to make a new job_nums.csv file.\nReview the memory and disk usage for these test jobs: condor_history $USER -limit 3 -af RequestMemory MemoryUsage RequestDisk DiskUsage. You may need to edit train.sub and training_controls.R to increase or decrease these values. You should make the values match across both files on both CHTC server and our server to avoid confusion later. Or just delete the batch and re-run mak_jobs.R\n\n\n\n6.5.3 Running jobs\n\nMake sure you have FTPed the full jobs_nums.csv to the CHTC server to replace the test batch.\nType condor_submit train.sub\nType condor_q to confirm that the number of jobs that were submitted matches your expectations\n\n\n\n6.5.4 Monitoring Running Jobs\n\nrun condor_q to monitor progress on your jobs.\nrun condor_q -hold to explore the reason for held jobs. If necessary, you may need to change the requested memory or disk space to get those jobs to complete. See below for more detail. condor_q -af HoldReason will provide more detail on why a job is held if needed.\nrun condor_q -run to explore running jobs\nrun condor_q -idle to explore idle jobs\nrun condor_q -analyze or condor_q JobId -better-analyze to determine why certain jobs are not running by performing an analysis on a per machine basis for each machine in the pool. The latter command produces more thorough analysis of complex requirements and shows the values of relevant job ClassAd attributes.\ncondor_release $USER will release all held jobs for the user. You can substitute batch or job number to release a subset of held jobs if needed\ncondor_rm $USER will remove/cancel all jobs for the user.\nYou can review the error files associated with the batch of jobs to detect and understand errors as well. Sort the files so that the files with errors (i.e., file switch file size &gt; 0) display last by typing ls error/error* -lSr If there are MANY (&gt; 60K) files, you may need to pipe the file names into ls by typing find error -name \"error_*\" | ls -lSr. You can view the contents of a non-zero error file using nano. e.g., nano error/error_1.err\nFlock/Glide jobs will sometimes not exit properly. These jobs are put on hold (in addition to jobs with insufficient memory/disk space). You can simply release these jobs and try again: condor_release $USER. Of course, you should first address any problems with memory or disk usage that resulted in holds.\n\n\n\n6.5.5 Removing a subset of jobs\nIt is possible to remove a subset of jobs using condor_rm with a constraint. It sounds like your jobs are in order based on their clusterID. To remove these jobs individually, it is possible to use condor_rm JobID. To remove a series of jobs, you can use:\ncondor_rm -constraint ‘ClusterId &gt; 1 && ClusterId &lt; 5’\nClusterID refers to the batch of jobs submitted using one submit file. After re-reading your email, it sounds like you want to remove a subset of jobs that all fall under one ClusterID. To do this, you can use something like: condor_rm -constraint ‘ProcId &gt; 1 && ProcId &lt; 5 && ClusterID == 15307921’ When typing condor_q, ClusterID is equivalent to the Batch_Name value. To remove the subset of jobs you want to remove, you will want to look at the values after the period in the Job_IDs column. The values after the period are the ProcessID (ProcID). For example, if I submitted a batch of jobs and it was assigned a cluster/batch name of 15307921 and I want to remove jobs 15307921.1, 15307921.2, and 15307921.3, I could use: condor_rm -const ’ProcId &gt; 1 && ProcId &lt; 5 && ClusterID == 15307921\n\n\n6.5.6 Editing Running Jobs\nAt times some (or all) jobs may be held if they require more memory or disk space than was requested in sub.sub. You can update these parameters and then release the held jobs.\n\nTo update memory, type condor_qedit [batch_name or job_id] RequestMemory [memory]. You can see the batch_name and job_ids by typing condor_q -hold Memory is quantified in MB.\n\nTo update disk space, type condor_qedit [batch_name or job_id] RequestDisk [space]. You can see the batch_name and job_ids by typing condor_q -hold Space is quantified in MB.\n\nType condor_release $USER to release all held jobs from the user.\nIf you expect that you will need the specified higher memory or disk space for the currently running jobs (not yet held), you can hold them by typing condor_hold $USER and then release them with condor_release $USER such that they will now find machine with the higher levels for these parameters.\n\n\n\n6.5.7 Transferring Jobs back to Our Server\n\nConfirm that you have the correct number of results files: ls results/results_* | wc -l\nReview the non-zero error files: ls error/error_* -lSr and nano error/error_1.csv\nConcatenate all the results files: head -n +1 results/results_1.csv &gt; batch_results.csv; ls results/results_*.csv | xargs awk 'FNR&gt;1' &gt;&gt; batch_results.csv. See tutorial on awk to understand its use for simple programming. See a tutorial on the use of xargs.\nNow FTP batch_results.csv and the log file to the output folder for this batch on our server.\n\nDo NOT delete results and error files until you have confirmed they look good by processing them in R."
  },
  {
    "objectID": "chtc.html#using-and-creating-containers-for-r-and-packages",
    "href": "chtc.html#using-and-creating-containers-for-r-and-packages",
    "title": "6  CHTC",
    "section": "6.6 Using and Creating Containers for R and Packages",
    "text": "6.6 Using and Creating Containers for R and Packages\n\n6.6.1 Full documetation from CHTC\nCHTC has full documentation of these steps. We are currently using this Docker image for base r. Chose current numbered version (e.g., 4.3.0) among tags.\n\n\n6.6.2 Use Existing Container\nWe have saved existing containers for training and for feature creation on our server in the CHTC folder (/CHTC/containers/train and /CHTC/containers/features). These folders include the sub and def files that were used to create these containers. The current/up-to-date container is named without an underscore. The _# are older versions with the highest number being the most recent old version. Likely not needed!\n\n\n6.6.3 Using Container with your Jobs\nNOTES: for now, CHTC says to not use the instructions from the above guide in your jobs’ sub file (e.g., “universe = container” and “container_image =”). That is the way of the future, however right now to run on the OSPool and CHTC, you’ll want to use this instead:\nuniverse = vanilla\n+SingularityImage = \"container.sif\"\nAnd then include the container.sif file in the transfer_input_files line. That should work seamlessly across the OSPool/CHTC. Maybe use this just to be safe: requirements = (PoolName == \"CHTC\") || (SINGULARITY_CAN_USE_SIF)\n\n\n6.6.4 Brief Steps for Creating a New Container\nHere is the steps in brief\n\ncreate or use and existing build.sub and .def file. See examples for train and features in the CHTC folder on the server.\nFTP these files to CHTC submit server\nRun an interactive sessions condor_submit -i build.sub, where you use your sub file\nBuild the apptainer: apptainer build train.sif train.def, where you name your .sif file and use your def file\nAfter the container is built, you can clear the cache: apptainer cache clean -f and then exit the interactive session. Your container should be returned to the root folder on chtc submit server (along with the log file). Consider whether to archive it on our server or if it was a one-time use for you."
  },
  {
    "objectID": "chtc.html#making-package-tars",
    "href": "chtc.html#making-package-tars",
    "title": "6  CHTC",
    "section": "6.7 Making package TARS",
    "text": "6.7 Making package TARS\nWe are no longer using tars (we use containers for R instead). However, if needed in the future, CHTC offers a detailed step-by-step walkthrough for making package tars."
  },
  {
    "objectID": "chtc.html#open-science-pool",
    "href": "chtc.html#open-science-pool",
    "title": "6  CHTC",
    "section": "6.8 Open Science Pool",
    "text": "6.8 Open Science Pool\nJJC plans to get an account directly for the OS Pool. We can access this pools through flock/glide BUT with an account, we can run twice as many jobs (using each account separately). May still just be easier to run using multiple lab accounts on CHTC but worth considering."
  },
  {
    "objectID": "chtc.html#common-condor-commands",
    "href": "chtc.html#common-condor-commands",
    "title": "6  CHTC",
    "section": "6.9 Common CONDOR commands",
    "text": "6.9 Common CONDOR commands\n\ncondor_submit train.sub\ncondor_q for quick review of queue for submitted jobs\ncondor_q -hold for quick review of held jobs\ncondor_q -af HoldReason for more detailed review of held jobs\ncondor_qedit [cluster id number] RequestMemory [memory] to increase memory. Example: condor_qedit 16892087 RequestMemory 20000. Can specific specific job with .# added to the ID. Memory is specified in MB in our training control files.\ncondor_release $USER to release all held jobs for user (e.g., after increasing memory)\ncondor_rm [jobid] or condor_rm $USER to remove a job or all jobs\ncondor_history $USER -limit 10 -af requestmemory memoryusage is an example of reviewing recent job history (past 10 in this example) for a subset of the history parameters. Can list all the parameters (long format) for a single job using condor_history 16892169.1 -l where the jobid is listed explicitly.\n\ncondor_hold $USER to hold all jobs running (e.g., to increase memory)."
  },
  {
    "objectID": "chtc.html#citing-chtc",
    "href": "chtc.html#citing-chtc",
    "title": "6  CHTC",
    "section": "6.10 Citing CHTC",
    "text": "6.10 Citing CHTC\nGuidance for citing CHTC in grants and papers."
  },
  {
    "objectID": "flowchart_demo.html",
    "href": "flowchart_demo.html",
    "title": "7  Flowcharts",
    "section": "",
    "text": "This is a short demo for making a flowchart in R.\nHere are two links to more information on the DiagrammeR function:\nhttps://bookdown.org/yihui/rmarkdown-cookbook/diagrams.html\nhttps://rich-iannone.github.io/DiagrammeR/graphviz_and_mermaid.html\nHere is a basic example of using DiagrammeR to create a flowchart of participant retention.\nThe process has 3 main parts:\n1. Define the nodes\n2. Define the edges\n3. Define node labels (content of nodes) using footnotes.\nNote: for this simple flowchart I am manually entering the number of particpants as a string. You can also use data in your dataset as content for the label.\nex. ‘Starting Sample = 216’ could also be str_c(‘Starting Sample =’, nrow(sample))\n\n\nDiagrammeR::grViz(\"\n  digraph {\n  graph []\n  \n  node [fontname = Helvetica, shape = rectangle, fixedsize = true, width = 2.5]\n  a [label = '@@1']\n  b [label = '@@2']\n  c [label = '@@3']\n  d [label = '@@4']\n  e [label = '@@5']\n  f [label = '@@6']\n  g [label = '@@7']\n\n  a -&gt; b -&gt; d -&gt; f\n  a -&gt; c\n  b -&gt; e\n  d -&gt; g\n  }\n  \n  [1]: 'Participants screened \\\\n n = 300'\n  [2]: 'Participants eligible \\\\n n = 250'\n  [3]: 'Participants ineligible \\\\n n = 50'\n  [4]: 'Participants enrolled \\\\n n = 215'\n  [5]: 'Participants did not enroll \\\\n n = 35'\n  [6]: 'Participants completed study \\\\n n= 175'\n  [7]: 'Participants discontinued \\\\n n = 40'\n  \") \n\n\n\n\n\nHere is a more complicated example of participant enrollment flow code, demonstrating how to code a) edges (lines) that connect to more than one node (box), b) more descriptive node labels, and c) manual line breaks in the node text.\n\ngrViz(\"digraph {\n\ngraph[layout = dot, rankdir = TB]  #top to bottom vs LR for left to right\n\n# general node definition\nnode [shape = rectangle, style = filled, fillcolor = LightBlue, fontsize=14]\n\n#specific nodes with label text specified later\nreddit [label = '@@1']\ncommunity [label = '@@2']\nclinician [label = '@@3']\ncraigslist [label = '@@15']\nunknown [label = '@@4']\nscreen [width = 3,label = '@@5']\nscreen_fail [shape = octagon, fillcolor= Red, height = 1.3, width = 1, label = '@@6']\nscreen_pass [width = 4, label = '@@7']\nfail_reasons [label = '@@8']\nenrolled [label = '@@9']\nnot_enrolled [shape = octagon, fillcolor= Red, height = 1.5, label = '@@10']\nnot_enrolled_why [label = '@@11']\non_study [label = '@@12']\noff_study [label = '@@13']\ndisposition [label = '@@14']\n\n\n#edge definitions (lines between boxes)\n{reddit community craigslist clinician unknown} -&gt; screen -&gt; {screen_fail screen_pass}\nscreen_fail -&gt; fail_reasons\nscreen_pass -&gt; {not_enrolled enrolled}\nnot_enrolled -&gt; not_enrolled_why\nenrolled -&gt; {on_study off_study}\noff_study -&gt; disposition\n}\n\n\n[1]: str_c('Reddit \\\\n(n = ', n_reddit, ')')\n[2]: str_c('Community \\\\n(n = ', n_community, ')')\n[3]: str_c('Clinician \\\\n(n = ', n_clinician, ')')\n[4]: str_c('Unknown \\\\n(n = ', n_unknown, ')')\n[5]: str_c('Screened \\\\n(n = ', n_reddit+n_community+n_clinician+n_craigsl+n_unknown, ')')\n[6]: str_c('Screen fail \\\\n(n = ', n_ineligible, ')')\n[7]: str_c('Screen pass \\\\n(n = ', n_eligible, ')')\n[8]: str_c('Screen fail reasons: \\\\n', 'No Android (n = ', sum(the_hist$no_android), ')\\\\n', 'Internet Number (n = ', sum(the_hist$yes_internet_num), ')\\\\n', 'Multiple or unreliable phones (n = ', sum(the_hist$maintain_phone, the_hist$multiple_phones), ')\\\\n', 'Under 18 (n = ', sum(the_hist$under_18), ')\\\\n', 'No MAT (n = ', sum(the_hist$no_mat), ')\\\\n', 'Not MAT adherent (n = ', sum(the_hist$daily_not_adhere, the_hist$monthly_not_adhere), ')\\\\n', 'MAT too short (n = ', sum(the_hist$mat_too_short), ')\\\\n', 'MAT too long (n = ', sum(the_hist$mat_too_long), ')\\\\n', 'Relapsed (n = ', sum(the_hist$relapse), ')\\\\n\\\\n', mult_inel, ' participants screened out\\\\non 2+ conditions')\n[9]: str_c('Enrolled \\\\n(n = ', nrow(all_digital), ')\\\\n', 'Scheduled (n = ', n_eligible_pending, ')')\n[10]: str_c('Not enrolled \\\\n(n = ', not_enrolled_digital, ')')\n[11]: str_c('Reasons not enrolled: Needs further exploration')\n[12]: str_c('On study \\\\n(n = ', all_digital %&gt;% filter(study_end_date &gt; today()) %&gt;% nrow(), ')')\n[13]: str_c('Off study \\\\n(n = ', all_digital %&gt;% filter(study_end_date &lt;= today()) %&gt;% nrow(), ')')\n[14]: str_c('Disposition: \\\\nCompleted (n = ', disposition %&gt;% filter(subid %in% all_digital$subid, disposition == 'complete') %&gt;% nrow(), ')\\\\n', 'Usable data (n = ', all_digital %&gt;% filter(study_end_date &lt;= today(), subid %in% usable_subs$subid) %&gt;% nrow(), ')\\\\n', 'Unusable (n = ', all_digital %&gt;% filter(study_end_date &lt;= today(), !(subid %in% usable_subs$subid)) %&gt;% nrow(), ')')\n[15]: str_c('Craigslist \\\\n(n = ', n_craigsl, ')')\n\")"
  },
  {
    "objectID": "git.html#common-git-commands",
    "href": "git.html#common-git-commands",
    "title": "8  Git",
    "section": "8.1 Common Git Commands",
    "text": "8.1 Common Git Commands\nNote: These commands will only work if you are in a git repo.\n\n8.1.1 Workflow\n\ngit status shows any files updated locally\ngit add [filename] add file to staging area\ngit add . adds all modified files to staging area\ngit commit create commit of staged files - this will prompt you to enter commit message. You can also use the -m flag to write your message directly with commit command (git commit -m \"updates xyz\").\ngit commit -am \"commit message\" will add all files and commit them in one step. However,\ngit push pushes your commits to github\ngit pull pulls updates from github (it is good practice to pull before commiting)\n\ngit mv &lt;oldname&gt; &lt;newname&gt; to rename and/or move a file without losing its link to its earlier history. Read more\ngit stash to stash changes; git stash pop to reapply stashed changes\n\n\n\n8.1.2 Repos\n\ngit clone [repo_url] clones git repo.\n\ngit init [repo_name] creates a new empty repo\n\n\n\n8.1.3 Branching\n\ngit branch shows local branches (git branch -a will show you all branches local and on github)\ngit checkout [branch_name] switches branches\ngit checkout -b [new_branch_name] switches to new branch (git branch [new_branch_name] creates new branch but doesn’t switch to it).\ngit branch -d [brand_name] deletes a local branch. This must be done from another branch or main.\ngit push origin -d [brach_name] deletes branch_name on remote/github (assumes remote is called origin, which it is for us).\n\n\n\n8.1.4 Log and Versioning\n\ngit log displays the most recent commits\ngit log --stat -[N] displays stats on the most recent N commits. Cleaner than log\ngit log [filename] displays commit history for a file. May have problems if the filename was ever changed. In that case consider, git log --follow -- [filename].  Can add–stat` for more info on commit\n\n\n\n8.1.5 Diffs\n\nwe use meld merge for file diffs\nmeld merge can do diffs on two files saved locally. For this, you can use the gui and select the files. For example, between a qmd file for a paper in a repo and another copy of that file with edits from a lab member saved outside the repo.\nmeld merge can also be set up to be used as the difftool for git. In Linux, add the following to your .gitconfig file\n\n[diff]\n    tool = meld\n[difftool]\n    prompt = false\n[difftool \"meld\"]\ncmd = meld \"$LOCAL\" \"$REMOTE\"\n\n# The order of the Meld GUI window panes can be controlled by the order of $LOCAL and $REMOTE in cmd.  JJC still not certain about this?\nOnce you have done this, git difftool will call meld. You can now use meld for diffs:\n\ngit difftool filename to compare local copy (not committed) of filename to head on repo\ngit difftool &lt;COMMIT_HASH&gt; filename to compare previous version of filename to head version on repo.\ngit difftool HEAD HEAD~2 filename to compare head version of filename on repo with version of filename two commits back.\ngit difftool &lt;COMMIT_HASH_1&gt; &lt;COMMIT_HASH_2&gt; filename to compare two versions of a file across two separate commits that are not the head on the repo."
  },
  {
    "objectID": "git.html#git-command-line-for-windows",
    "href": "git.html#git-command-line-for-windows",
    "title": "8  Git",
    "section": "8.2 Git Command Line for Windows",
    "text": "8.2 Git Command Line for Windows\nThe recommended terminal for using the Git command line on Windows is Git Bash. You can have Git command line and Git Desktop installed on the same machine and they mostly do not affect each other (see notes below).\n\n8.2.1 Installation\nDuring installation, you will be given several options:\n\nSelect the default text editor. It defaults to Vim, but you can select any text editor you have installed on your system.\nOverride branch name for new repos created with git init. It defaults to “master” but you can set your own. This does not affect existing repos. I selected to override and use “main” which is more familiar to me.\nAdjust path environment. The most cautious choice is to use Git soley from Git Bash; I selected this as I do not plan on using any other 3rd party software.\nChange SSH executable & backend. The default is the bundled OpenSSH software and crt file.\nConfigure line endings. As Windows and Unix use different line-end characters, I recommend using the default which is to check out as Windows and commit at Unix. This will prevent issues for other users not on Windows.\nSelect terminal emulator. I selected the default MinTTY option to make sure I didn’t mistake a cmd terminal window for my git terminal.\nChoose behavior of git pull. Leave it on the default unless you know what effects the other options may have.\nChoose credential manager. Choose the default which is the bundled Git Credentials Manager. You will then be able to authenticate once and stay logged in.\nExtra options. By default, “Enable file system caching” is checked and “Enable symbolic links” is unchecked. Leave as is unless you know what each option affects.\nExperimental options. Leave these unchecked unless you know what you’re doing!\n\n\n\n8.2.2 Windows Notes\n\nWhen first attempting to interact with a repo (either clone/pull/push) Windows will pop up a Git Credentials Window for you to authenticate. Select “Use website” and it will open a browser window the same as happens with Github Desktop. It takes a moment for the connection to be made before you will be able to click the green button to authenticate.\nWhen navigating between directories, if a directory has a space in the name, you must enclose it in single quotes (not backtics)\nOccasionally I have typed unequal quotes, ie cd 'My Documents\" and although GitBash acts as if the command was accepted (showing a new command prompt), nothing happens. The only solution I have found is to close and re-open GitBash.\npwd is a shortcut to print the working directory."
  },
  {
    "objectID": "git.html#git-filter-repo",
    "href": "git.html#git-filter-repo",
    "title": "8  Git",
    "section": "8.3 git filter-repo",
    "text": "8.3 git filter-repo\ngit filter-repo is a tool that can be used to remove large or sensitive files from a repository. It removes the file from all caches, commits, and revision histories without affecting the rest of the repo.\nOne note: If you commit a large file and make no other changes to the repo in that commit, then you use this tool to remove all traces of that file, the entire commit WILL disappear from the revision history. The commit will remain as long as ANY other file was also touched by the commit.\n\n8.3.1 Installation\n\nYou must first install Python. In GitBash run python3and it will install it from the Windows Store.\nFind the location of your git installation by running git --exec-path in GitBash.\nSave this file into your Downloads folder if your OS won’t allow you to save directly to the git installation location.\nUsing File Explorer, change the file name to remove the .txt extension (in Windows 11, at least, it will not download without adding that file extension.)\nCopy the renamed file into your git installation folder if you weren’t already able to save it there. You will be prompted to provide administrative authorization to permit the copy.\ncd into a repo and type git filter-repo to test. If the installation was successful it will say no arguments specified\n\n\n\n8.3.2 Usage\nFirst you will need to know the full repo path & name of the large or sensitive files you wish to delete. To do this, you can browse the previous commits in the repo to identify where they were first added. (Technically, you can get the path/name of the large file from any commit touching that file, but getting it from the initial commit makes sure you don’t miss any renames or moves).\nYou could also run the following command to find XX largest objects in repo:\ngit rev-list --objects --all \\  \n  | grep \"$(git verify-pack -v .git/objects/pack/*.idx \\  \n           | sort -k 3 -n \\  \n           | tail -XX \\  \n           | awk '{print$1}')\"\nThis outputs the path names in a format which is easy to copy.\nOnce you have the path/file names, follow the commands here to remove each file and add them to gitignore so they don’t accidentally get re-committed. You can run an entire list of git filter-repo commands to remove many files at once."
  },
  {
    "objectID": "git.html#github-website-tools",
    "href": "git.html#github-website-tools",
    "title": "8  Git",
    "section": "8.4 Github Website Tools",
    "text": "8.4 Github Website Tools\n\n8.4.1 Create Personal Access Token\nOn the website, go to Account Settings &gt; Developer Settings &gt; Personal Access Tokens &gt; Token (Classic). There is a Beta version that allows more fine-grained access but I haven’t experimented with that yet.\nHit “Generate new token (Classic)”. You can specify what this token will be used for and select various permissions to allow for this token.\nWhen the token is generated, you must save it somewhere - Github won’t let you see it again. You can then use this token for certain privileged access actions, such as importing another repo into a clean repo repo.\n\n\n8.4.2 Import a repo\nThis action is used when you want to copy another repo into a new repo. It copies ALL past fils, commits, and history, but any actions taken to the new repo will not affect the old repo in the way a branch would.\n\nCreate a new repo via the website “New repo” button. Give it whatever name and privacy settings are desired.\nOn the next page, to populate your repository, choose “Import code from another repository”.\nIt will then ask for “Your old repository’s clone URL”. If you are importing another github repo, the plain repo URL is all that’s needed i.e. “https://github.com/jjcurtin/analysis_risk” will import an exact copy of the Risk1 analysis repo. Click “Begin Import”.\nYou will be asked to provide your Login (your github email, NOT the password) and Private Access Token (see above)."
  },
  {
    "objectID": "linux_install.html#install-os",
    "href": "linux_install.html#install-os",
    "title": "9  Installing Linux",
    "section": "9.1 Install OS",
    "text": "9.1 Install OS\nhttps://ubuntu.com/tutorials/install-ubuntu-desktop#1-overview"
  },
  {
    "objectID": "linux_install.html#install-key-support-apps",
    "href": "linux_install.html#install-key-support-apps",
    "title": "9  Installing Linux",
    "section": "9.2 Install key support apps",
    "text": "9.2 Install key support apps\nsudo apt install git sudo apt install vim"
  },
  {
    "objectID": "linux_install.html#create-and-edit-aliases",
    "href": "linux_install.html#create-and-edit-aliases",
    "title": "9  Installing Linux",
    "section": "9.3 Create and edit aliases",
    "text": "9.3 Create and edit aliases"
  },
  {
    "objectID": "linux_install.html#r",
    "href": "linux_install.html#r",
    "title": "9  Installing Linux",
    "section": "9.4 R",
    "text": "9.4 R\nsudo apt install -y –no-install-recommends software-properties-common dirmngr wget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc sudo add-apt-repository “deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/” sudo apt install -y r-base r-base-core r-recommended r-base-dev sudo apt install libcurl4-openssl-dev sudo apt install libfontconfig1-dev sudo apt install libxml2-dev sudo apt install libharfbuzz-dev libfribidi-dev\nwget https://download1.rstudio.org/electron/jammy/amd64/rstudio-2023.03.0-386-amd64.deb sudo apt install -f ./rstudio-2023.03.0-386-amd64.deb\ninstall.packages(“devtools”) library(devtools) install.packages(“tidyverse”)\nhttps://www.r-bloggers.com/2022/08/installation-of-r-4-2-on-ubuntu-22-04-1-lts-and-tips-for-spatial-packages/\nhttps://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-22-04\nhttps://computingforgeeks.com/how-to-install-r-and-rstudio-on-ubuntu-debian-mint/"
  },
  {
    "objectID": "linux_install.html#quarto",
    "href": "linux_install.html#quarto",
    "title": "9  Installing Linux",
    "section": "9.5 Quarto",
    "text": "9.5 Quarto\n\nDownload latest version of Quarto\ninstall using sudo apt install &lt;package path&gt; or sudo dpkg -i &lt;package path&gt;\n\nhttps://docs.posit.co/resources/install-quarto/\nhttps://www.cyberciti.biz/faq/how-to-install-curl-command-on-a-ubuntu-linux/"
  },
  {
    "objectID": "linux_install.html#zotero",
    "href": "linux_install.html#zotero",
    "title": "9  Installing Linux",
    "section": "9.6 Zotero",
    "text": "9.6 Zotero\n\nsudo apt update\nsudo apt upgrade\nsudo snap install zotero-snap\n\nAfter zotero is installed, you can synch to the Addiction Research Lab library. Go to menu edit:preferences:synch. Username is jjccurtin. Ask John or Susan for the password."
  },
  {
    "objectID": "linux_install.html#slack",
    "href": "linux_install.html#slack",
    "title": "9  Installing Linux",
    "section": "9.7 Slack",
    "text": "9.7 Slack\nSlack is easily installed from the Ubuntu Software Center. Open up the software center. Search for Slack. Install. Done.\n\n9.7.1 pdfs\n\nsudo snap install evince for viewing pdfs\nsudo apt-get install qpdf for manipulating pdfs (e.g., extract pages)"
  },
  {
    "objectID": "linux_install.html#global-protect",
    "href": "linux_install.html#global-protect",
    "title": "9  Installing Linux",
    "section": "9.8 Global Protect",
    "text": "9.8 Global Protect\n\n[Install] (https://kb.wisc.edu/helpdesk/105971)\n[]"
  },
  {
    "objectID": "linux_install.html#meld-merge-for-file-diffs",
    "href": "linux_install.html#meld-merge-for-file-diffs",
    "title": "9  Installing Linux",
    "section": "9.9 Meld Merge for file diffs",
    "text": "9.9 Meld Merge for file diffs\n\ndownload and install meld merge\nadd the following to your .gitconfig file\n\n[diff]\n    tool = meld\n[difftool]\n    prompt = false\n[difftool \"meld\"]\ncmd = meld \"$LOCAL\" \"$REMOTE\"\n\n# The order of the Meld GUI window panes can be controlled by the order of $LOCAL and $REMOTE in cmd"
  },
  {
    "objectID": "linux_install.html#csv",
    "href": "linux_install.html#csv",
    "title": "9  Installing Linux",
    "section": "9.10 CSV",
    "text": "9.10 CSV\nhttps://www.tadviewer.com/\nhttps://www.moderncsv.com/"
  },
  {
    "objectID": "linux_install.html#mount-shares",
    "href": "linux_install.html#mount-shares",
    "title": "9  Installing Linux",
    "section": "9.11 Mount Shares",
    "text": "9.11 Mount Shares\n\nsudo apt-get install cifs-utils\ncreate directories within ~/mnt/ for each share.\nsave credentials file for synology (.synology_credentials) or research drive (.researchdrive_credentials) at /root/. These should include username=, password= (and for research drive, domain=ad.wisc.edu)\ncreate an alias for the command for each share to mount. Get it from John"
  },
  {
    "objectID": "linux_install.html#set-up-ssh-client-and-server",
    "href": "linux_install.html#set-up-ssh-client-and-server",
    "title": "9  Installing Linux",
    "section": "9.12 Set up SSH Client and Server",
    "text": "9.12 Set up SSH Client and Server\nhttps://ubuntu.com/server/docs/service-openssh"
  },
  {
    "objectID": "linux_install.html#creating-ssh-passkeys",
    "href": "linux_install.html#creating-ssh-passkeys",
    "title": "9  Installing Linux",
    "section": "9.13 Creating SSH passkeys",
    "text": "9.13 Creating SSH passkeys\nYou can create an ssh key to ssh without the need to provide username and password. In our lab, these are useful to ssh to CHTC or for git shh to GitHub.\nTo create the key\n\nOpen a terminal and type ssh-keygen -t ed25519.\nAccept the defaults by repeatedly pressing enter and this will create a key with defauult names .ssh/id_ed25519, and .ssh/id_ed25519.pub.\nAfter creating the keys, you may need to change their permissions.\n\n\nchmod 644 id_ed25519.pub\nchmod 600 id_ed25519\n\nTo use this key with CHTC\n\nCreate or edit personal CHTC configuration file at ~/.ssh/config. Run the following at the terminal:\n\n\n# Let's create (or add to) our SSH client configuration file. \necho \"\nHost *.chtc.wisc.edu\n  # Turn ControlMaster on\n  ControlMaster auto\n  # ControlMaster connection will persist\n  # for 2 hours of idleness, after which\n  # it will disconnect\n  ControlPersist 2h\n  # Where to store files that represent\n  # the ControlMaster persistent connections\n  ControlPath ~/.ssh/connections/%r@%h:%p\" &gt;&gt; ~/.ssh/config\n\n\nIn the same ~/.ssh/config directory, make a folder called connections\n\nmkdir -p ~/.ssh/connections\n\nOpen the public key file (id_25519.pub) and copy the content.\nSSH to CTHC\n\nssh netid@submit-1.chtc.wisc.edu\n\nCreate or edit .ssh/authorized_keys\nPaste your public key info at the end of this file.\n\nTo use this key with Github\n\nGo to your settings (point at your profile picture and select settings.\nSelect SSH and GPG Keys\nClick New SSH Key, give it a title, and paste the public key info into Key box.\n\nFor more info\n\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\nhttps://github.com/settings/keys\nhttps://www.beyondtrust.com/blog/entry/ssh-key-management-overview-6-best-practices"
  },
  {
    "objectID": "linux_install.html#sound-mixer-settings",
    "href": "linux_install.html#sound-mixer-settings",
    "title": "9  Installing Linux",
    "section": "9.14 Sound mixer settings",
    "text": "9.14 Sound mixer settings\ninstall pavucontrol to get mic on zoom to work\nalsamixer from terminal may help"
  },
  {
    "objectID": "linux_install.html#vnc-for-remote-access",
    "href": "linux_install.html#vnc-for-remote-access",
    "title": "9  Installing Linux",
    "section": "9.15 VNC for Remote Access",
    "text": "9.15 VNC for Remote Access\nhttps://kb.wisc.edu/biochem/it/page.php?id=127360"
  },
  {
    "objectID": "linux_install.html#ssh-to-office-computer",
    "href": "linux_install.html#ssh-to-office-computer",
    "title": "9  Installing Linux",
    "section": "9.16 SSH to office computer",
    "text": "9.16 SSH to office computer\nhttps://linuxhint.com/enable-use-ssh-ubuntu/\nuse username for hostname\n\n9.16.1 X11 forwarding\nX11 forwarding is used in SSH to display GUI for app (e.g., rstudio) on remote computer (e.g., office computer). To enable X11 forwarding, need to edit /etc/ssh/sshd_config on remote computer to indicate: - X11Forwarding yes\nMay also want to set - X11DisplayOffset 10 - X11UseLocalhost yes - TCPKeepAlive yes\nMay need to install xauth on remote computer.\nNeed to use -X flag with ssh from local computer. Can then open GUI for remote app (e.g.. rstudio)\n\n\n9.16.2 VNC\n\nDocumentation on how to install tightvnc on host.\nStart vncserver on host with specific resolution: vncserver -geometry 2560x1080 -depth 24\nOn client, can use Remmina with SSH."
  },
  {
    "objectID": "linux_install.html#customize-cli-prompt",
    "href": "linux_install.html#customize-cli-prompt",
    "title": "9  Installing Linux",
    "section": "9.17 Customize CLI prompt",
    "text": "9.17 Customize CLI prompt\nThis will set up a green prompt with relative path for current directory.\nPS1=“$ (https://git-scm.com/download/win).\nThis is NOT needed if you are installing Linux as your OS."
  },
  {
    "objectID": "linux_use.html#general-short-cuts",
    "href": "linux_use.html#general-short-cuts",
    "title": "10  Using Linux",
    "section": "10.1 General Short Cuts",
    "text": "10.1 General Short Cuts\n\nsuper+tab switches between windows\nsuper+left/right arrow fits active window to left or right of screen\nctrl+alt+t opens a new terminal window\nctrl+d closes a terminal window"
  },
  {
    "objectID": "linux_use.html#terminal-short-cuts",
    "href": "linux_use.html#terminal-short-cuts",
    "title": "10  Using Linux",
    "section": "10.2 Terminal Short Cuts",
    "text": "10.2 Terminal Short Cuts\n\ntab autocompletes from what you have started to type\nctrl+c breaks out of a command or process\nctrl+d logs out of current terminal\n`ctrl+l clears screen\nctrl+a moves cursor to beginnng of line\nctrl+e moves cursor to the end of line\nctrl+u clears the current line\nctrl+p or up arrow scrolls through previous commands\nctrl_n or down arrow scrolls forward through commands\nctrl+shift+c copies highlighted text\nctrl+shift+v pastes copied text"
  },
  {
    "objectID": "linux_use.html#control-processes",
    "href": "linux_use.html#control-processes",
    "title": "10  Using Linux",
    "section": "10.3 control processes",
    "text": "10.3 control processes\n\ncommand & to launch program in background of terminal\nfg %1 to move program to foreground\nbg %1 to move to background\nkill %1 (see chap 10 in linux book)"
  },
  {
    "objectID": "linux_use.html#pdf-manipulation",
    "href": "linux_use.html#pdf-manipulation",
    "title": "10  Using Linux",
    "section": "10.4 Pdf manipulation",
    "text": "10.4 Pdf manipulation\nWe use evince [filename.pdf] to view pdfs\nwe use qpdf --empty --pages infile.pdf 1-5 -- outfile.pdf to extract pages from a pdf"
  },
  {
    "objectID": "linux_use.html#quarto",
    "href": "linux_use.html#quarto",
    "title": "10  Using Linux",
    "section": "10.5 Quarto",
    "text": "10.5 Quarto"
  },
  {
    "objectID": "linux_use.html#markdown",
    "href": "linux_use.html#markdown",
    "title": "10  Using Linux",
    "section": "10.6 Markdown",
    "text": "10.6 Markdown\nYou will need to install pandoc to render markdown to pdf: sudo apt-get install pandoc texlive-latex-base texlive-fonts-recommended texlive-extra-utils texlive-latex-extra.\nUse pandoc [infile.md] -o [outfile.pdf] to render infile.md to outfile.pdf.\nNote also that the ReText app can render markdown to pdf (and html) as well if you don’t want to use the terminal."
  },
  {
    "objectID": "linux_use.html#firefox",
    "href": "linux_use.html#firefox",
    "title": "10  Using Linux",
    "section": "10.7 Firefox",
    "text": "10.7 Firefox\nYou can view an html file in firefox from terminal using firefox [filename]"
  },
  {
    "objectID": "linux_use.html#common-commands",
    "href": "linux_use.html#common-commands",
    "title": "10  Using Linux",
    "section": "10.8 Common Commands",
    "text": "10.8 Common Commands\n\nwc, uniq, head, tail, |, &gt;, &gt;&gt;, less, sort, grep, cat, man, help, –help, type, which, echo\nls -lSr to list files sorted by size (with larger sizes later: r). Useful to find the non-zero error files. Can have issues when applied to large numbers of files (&gt; 60K). See use of find and xargs below if needed.\ncd - changes tio previous directory\nmv to move files between directories. can use .. as target to move file to home directory. e.g., mv results_* ..\n&gt; redirect standard output to a new file (creates file if does not exist; writes over file contents if it does exist). &gt;&gt; redirect standard output to append to a file\nrm to remove file(s). rm -r to remove non-empty directory\ncat filename_* &gt; all_files.csv to concatenate all files into one file.\nless views file contents\n| is pipe operator\nwc is word count. wc -l counts lines\nchmod +x get_missing_jobs.sh to change permissions on get_missing_jobs.sh to run it. ./get_missing_jobs.sh to run it.\nfind -maxdepth 1 -name \"results_*.csv\" | wc -l will find results_*.csv in local folder (maxdepth 1) and pipe them into a word count that counts lines (-l)\ncat job_nums.csv | wc -l reads contents of job_nums.csv and pipes to a word count that counts lines (-l)\nfind -maxdepth 1 -name \"results_*.csv\" | ls -lSr gets around the too many arguments issue. Find searches recursively by default (override with maxdepth if needed), whereas ls searches just . or the specified directory (e.g., ./results)\nSee tutorial on awk to understand its use for simple programming. See a tutorial on the use of xargs.\nprintf to send formatted text to standard output or to a file\n\nprintf \"John is %s\\n\" \"nice\"\nprintf \"John is %d years old\" 54\nprintf \"hello world\\nIt is John!\" &gt; out.txt)\n\nman [command] to open manual for command\nsdiff file1 file2 - Compare two files side by side.\nvimdiff file1 file2 - Highlight the differences between two files in the vim editor.\ntar [-] c|x|t f tarfile [pattern] - Create, extract or list contents of a tar archive using pattern, if supplied.\ndu -h - Display sizes in human readable format. For example, 1.2M, 3.7G, etc.\nhead, tail, and sort work as expected. Remember to use -n with sort if you want to do a numeric (rather than text) sort. Sort also takes -r for reverse. Use pipe to pipe in a vector of numbers or text. Use -1 with head or tail to get the first (or last) value in series."
  },
  {
    "objectID": "linux_use.html#compressing-and-archiving-files",
    "href": "linux_use.html#compressing-and-archiving-files",
    "title": "10  Using Linux",
    "section": "10.9 Compressing and archiving files",
    "text": "10.9 Compressing and archiving files\n\n`gzip foo.txt - Compress foo.txt. The resulting compressed file is named file.txt.gz. -r to compress subdirectories when compressing a directory rather than file.\ngunzip foo.txt - Uncompress foo.txt.gz (no need to append .gz).\ngunzip foo.txt -c | less to view contents of foo.txt without decompressing it\ntar cf playground.tar playground make archive of playground directory. r rather than c to append rather than create new archive.\ntar czf playground.tgz playground to archive and compress (could also name playground.tar.gz)\ntar xf playground2.tar to extract files from archive\nsee linux book, chapter 18 for more details"
  },
  {
    "objectID": "linux_use.html#ftp",
    "href": "linux_use.html#ftp",
    "title": "10  Using Linux",
    "section": "10.10 FTP",
    "text": "10.10 FTP\n\nuse sftp at command line. e.g., sftp submit-1.chtc.wisc.edu\ncan use command line to review local and remote computers.\nFor local lls, lcd, lpwd are the three most useful commands\nFor remote ls, cd, pwd\nUse get foo.txt to copy foo.txt from remote to local director\nUse put foo.txt to copy foo.txt from local directory to remote directory\nexit when done\nCan set up a ssh key to log in without credentials to CHTC."
  },
  {
    "objectID": "linux_use.html#ssh",
    "href": "linux_use.html#ssh",
    "title": "10  Using Linux",
    "section": "10.11 SSH",
    "text": "10.11 SSH\n\nuse ssh at command line. e.g., ssh submit-1.chtc.wisc.edu\nCan set up a ssh key to log in without credentials to CHTC, Github, etc."
  },
  {
    "objectID": "linux_use.html#kill-a-frozen-app",
    "href": "linux_use.html#kill-a-frozen-app",
    "title": "10  Using Linux",
    "section": "10.12 Kill a frozen app",
    "text": "10.12 Kill a frozen app\nPress Alt + F2 . Type xkill and hit Enter. The cursor will turn into a small ‘x’. Left click any window to kill the process associated with that window."
  },
  {
    "objectID": "vim.html#exit-and-save",
    "href": "vim.html#exit-and-save",
    "title": "11  Vim",
    "section": "11.1 Exit and Save",
    "text": "11.1 Exit and Save\n\n:x exits and saves\n:w saves without exit\n:w filename saves file as filename\n:q! exits without save"
  },
  {
    "objectID": "vim.html#run-commands",
    "href": "vim.html#run-commands",
    "title": "11  Vim",
    "section": "11.2 Run commands",
    "text": "11.2 Run commands\n\n:!CMD where CMD is command. e.g.., !ls"
  },
  {
    "objectID": "vim.html#navigating-document-in-default-command-mode",
    "href": "vim.html#navigating-document-in-default-command-mode",
    "title": "11  Vim",
    "section": "11.3 Navigating document in Default (Command) Mode",
    "text": "11.3 Navigating document in Default (Command) Mode\nRemember to enter command mode by pressing esc - 0 moves the cursor to the start of line - $ moves cursor to end of line - Move cursor left (h), down(j), up (k), or right (l)\n\ngg for top of document\nG for bottom of document\nnG to move to line number n. CTRL-g shows line numbers in footer of doc.\nH for top of window, M for middle of window, and L for bottom of window\nw moves forward to the beginning of the next word.\nb moves backwards to the beginning of the previous word.\n( and ) move by sentences, either backward or forward.\n{ and } move by paragraphs."
  },
  {
    "objectID": "vim.html#inserting",
    "href": "vim.html#inserting",
    "title": "11  Vim",
    "section": "11.4 Inserting",
    "text": "11.4 Inserting\n\ni Insert text before the cursor\na Insert text after cursor\nA Append text to end of current line. - I Insert text at beginning of line.\no Open blank line below cursor for text. - O Open blank line above cursor for text.\np puts the Vim register (from delete) after cursor (if full line, on next line).\nrx replaces the character at the cursor with ‘x’\nR replaces multiple characters. Type ESC when done.\nce deletes until end of word and places you in insert. Press ESC when done\nc$ deletes until end of line and places you in insert. Press ESC when done\n:%s/old/new/gc - replaces old with new in full doc with prompt for replace.\n:r filename to insert text in filename above cursor"
  },
  {
    "objectID": "vim.html#deleting",
    "href": "vim.html#deleting",
    "title": "11  Vim",
    "section": "11.5 Deleting",
    "text": "11.5 Deleting\n\nx deletes the character under the cursor\ndw deletes from cursor to start of next word (including space spearator). d2w deletes from cursor to end of second word, etc.\nde delets from curors to end of current for\ndd deletes the line. 2dd deletes two lines.\nd$ deletes from cursor to end of line.\nu to undo the last command. CTRL-R for redo -U to undo all fixes on a line."
  },
  {
    "objectID": "vim.html#spell-check",
    "href": "vim.html#spell-check",
    "title": "11  Vim",
    "section": "11.6 Spell check",
    "text": "11.6 Spell check\n\n:set spell – Turn on spell checking\n:set nospell – Turn off spell checking\n]s – Jump to the next misspelled word\n[s – Jump to the previous misspelled word\nz= – Bring up the suggested replacements\nzg – Good word: Add the word under the cursor to the dictionary\nzw – Woops! Undo and remove the word from the dictionary"
  },
  {
    "objectID": "vim.html#search-in-vim",
    "href": "vim.html#search-in-vim",
    "title": "11  Vim",
    "section": "11.7 Search in VIM",
    "text": "11.7 Search in VIM\n\n/text to search forward for text. Type ENTER to exit to that text.\n?text to search backward for text.\nn to find next instance of text (after ENTER)\nN to find previous instance of text (after ENTER)\n\nFor search and replace\n\n`%s///options\noptions include g for replace all, c for confirmation and i for case insensitive"
  },
  {
    "objectID": "vim.html#visual-selection",
    "href": "vim.html#visual-selection",
    "title": "11  Vim",
    "section": "11.8 Visual selection",
    "text": "11.8 Visual selection\n\nv to select text. Move cursor around with hjkl keys\nthen d to delete (can later p(ut) it somewhere if needed)\nor y to yank (copy) so you can later p(ut) it somewhere\nor w to write to separate file"
  },
  {
    "objectID": "vim.html#copy",
    "href": "vim.html#copy",
    "title": "11  Vim",
    "section": "11.9 Copy",
    "text": "11.9 Copy\n\ny to yank (copy) selction (use with v for visual selection)\nyw to yank a word\nyy to yank a line"
  },
  {
    "objectID": "vim.html#working-with-multiple-files",
    "href": "vim.html#working-with-multiple-files",
    "title": "11  Vim",
    "section": "11.10 Working with multiple files",
    "text": "11.10 Working with multiple files\nVim can open multiple files in separate buffers. This can be done at the start by providing multiple filenames to vim (e.g., vim file1.md file2.md)\nAlternatively, additional files can be opened for editting later (:e file2.txt).\nMoving between buffers\n\nbn moves to next buffer\nbp moves to previous buffer\n:buffers displays all open buffers\n: buffer 1 allows switch to buffer 1 (or any other number) if there are many buffers open\n:bd deletes the current buffer. Will fail unless buffer has first been saved (or no changes made)\n\nyank/delete/put will work between buffers"
  },
  {
    "objectID": "vim.html#command-line-in-vim",
    "href": "vim.html#command-line-in-vim",
    "title": "11  Vim",
    "section": "11.11 Command line in VIM",
    "text": "11.11 Command line in VIM\nSwitch to command line from normal mode by typing :\nYou can then use:\n\npwd to print the current working director\ncd to change the working directory for the vim shell\nlcd to change the working directory for the specific buffer you are in"
  },
  {
    "objectID": "vim.html#render-files",
    "href": "vim.html#render-files",
    "title": "11  Vim",
    "section": "11.12 Render files",
    "text": "11.12 Render files\nWe tend to use either md or qmd files for writing, code, etc. Our .vimrc file turns on markdown highlighting for these files if saved with .md or ..qmd extensions. qmd is preferred because it works with RStudio as well.\nThese files can be rendered to html or pdf if desired.\n\nquarto render file.qmd to render to html\nquarto render file.qmd --to pdf to render to pdf\n\nWe can use a full yaml header for more fancy output. We have templates for apa manuscripts, letterhead, and a generally nice format pdf output if desired. Just paste the yaml at the top of the file."
  },
  {
    "objectID": "vim.html#installing-plugins",
    "href": "vim.html#installing-plugins",
    "title": "11  Vim",
    "section": "11.13 Installing plugins",
    "text": "11.13 Installing plugins\nIf the plugin is on github, simply clone it using the github url into the vim plugin folder: /home/jjcurtin/.vim/pack/vendor/start\nAnd you are done!"
  },
  {
    "objectID": "vim.html#learing-vim",
    "href": "vim.html#learing-vim",
    "title": "11  Vim",
    "section": "11.14 Learing VIM",
    "text": "11.14 Learing VIM\n\nrun vimtutor\nbooks: https://iccf-holland.org/vim_books.html"
  },
  {
    "objectID": "bash_scripting.html#getting-started",
    "href": "bash_scripting.html#getting-started",
    "title": "12  Bash Scripting",
    "section": "12.1 Getting Started",
    "text": "12.1 Getting Started\n\nstart scripts with shebang (#!/bin/bash)\nuse comments (#)\nmake executable fie everyone (chmod 755 foo.sh) or just you (chmod 700 foo.sh)\nexecute in subshell using ./foo.sh (if in current directory)\nsource in current shell using source foo.sh or . foo.sh (again if in current directory)\nConsider where to save\n\ncan be run from anywhere if saved in PATH (~/bin for you or /usr/local/bin for everyone)\nneed to type full filename and path to run if not in path"
  },
  {
    "objectID": "bash_scripting.html#general",
    "href": "bash_scripting.html#general",
    "title": "12  Bash Scripting",
    "section": "12.2 General",
    "text": "12.2 General\nassignment to variable in subprocess - x=1 - foo=“yes” - echo $foo - fn=foo.txt\nassignment in environment (available to all processes) - export x=1"
  },
  {
    "objectID": "shell_expansions.html#wildcards",
    "href": "shell_expansions.html#wildcards",
    "title": "13  Shell Expansions",
    "section": "13.1 Wildcards",
    "text": "13.1 Wildcards\n\n\nMatches any sequence of characters.\n\n? Matches a single character.\n[…] Matches any character within the brackets.\n[^...] Matches any character NOT in the brackets."
  },
  {
    "objectID": "shell_expansions.html#tilde-expansion",
    "href": "shell_expansions.html#tilde-expansion",
    "title": "13  Shell Expansions",
    "section": "13.2 Tilde Expansion",
    "text": "13.2 Tilde Expansion\nTilde Expansion:\n\n~ Expands to the home directory of the current user.\n~username Expands to the home directory of the specified username."
  },
  {
    "objectID": "shell_expansions.html#variableparameter-expansion",
    "href": "shell_expansions.html#variableparameter-expansion",
    "title": "13  Shell Expansions",
    "section": "13.3 Variable/Parameter Expansion",
    "text": "13.3 Variable/Parameter Expansion\nShell variables are placeholders for storing data. When you reference a variable, the shell expands it to its stored value.\n\n$variable: Expands to the value of the specified variable.\n${variable}: Use curly braces for disambiguation.\n\nhttps://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Shell-Parameter-Expansion\nhttps://opensource.com/article/17/6/bash-parameter-expansion"
  },
  {
    "objectID": "shell_expansions.html#command-substitution",
    "href": "shell_expansions.html#command-substitution",
    "title": "13  Shell Expansions",
    "section": "13.4 Command Substitution",
    "text": "13.4 Command Substitution\nCommand substitution allows you to execute a command and replace it with its output. - $(command): Executes the command and substitutes its output.\nexamples:\nfiles_count=$(ls -l | wc -l) echo \"Number of files: $files_count\""
  },
  {
    "objectID": "shell_expansions.html#arithmetic-expansion",
    "href": "shell_expansions.html#arithmetic-expansion",
    "title": "13  Shell Expansions",
    "section": "13.5 Arithmetic Expansion",
    "text": "13.5 Arithmetic Expansion\nArithmetic expressions enclosed in double parentheses $((…)) are evaluated and the result is expanded.\nExample:\nPrints: y is 10\nx=5 y=$((x * 2)) echo \"y is $y\""
  },
  {
    "objectID": "shell_expansions.html#brace-expansion",
    "href": "shell_expansions.html#brace-expansion",
    "title": "13  Shell Expansions",
    "section": "13.6 Brace Expansion",
    "text": "13.6 Brace Expansion\nBrace expansion generates multiple strings by specifying a sequence or multiple options inside curly braces.\n{a,b,c}: Expands to “a”, “b”, and “c”. {start..end}: Expands a alphanumerical range.\nExamples:\nPrints: apple banana cherry\necho {apple,banana,cherry}\nPrints: 1 2 3 4 5\necho {1..5}"
  },
  {
    "objectID": "shell_expansions.html#common-applications",
    "href": "shell_expansions.html#common-applications",
    "title": "13  Shell Expansions",
    "section": "13.7 Common Applications",
    "text": "13.7 Common Applications\n\n13.7.1 Remove the extension (.zip) from all the filenames\nNote: the – protects against filenames that begin with - and would appear to be an option otherwise.\nfor f in *.zip; do mv -- \"$f\" \"${f%.zip}\"; done\n\n\n13.7.2 Replace extension (.foo to .bar) for all filenames\nfor f in *.foo; do mv -- \"$f\" \"${f%.foo}.bar\"; done\n\n\n13.7.3 Remove prefix abc_ from all filenames\nfor f in abc_* ; do mv -- \"$f\" \"${f#abc_}\"; done\n\n\n13.7.4 Replace all spaces with underscores\nfor f in *\\ *; do mv -- \"$f\" \"${f// /_}\"; done\n\n\n13.7.5 Convert filenames to all lowercase\nfor f in *[[:upper:]]*; do mv -- \"$f\" \"${f,,}\"; done"
  },
  {
    "objectID": "globalprotect_mapping.html#global-protect",
    "href": "globalprotect_mapping.html#global-protect",
    "title": "14  Global Protect and Mapping the Network Server",
    "section": "14.1 Global Protect",
    "text": "14.1 Global Protect\nAfter you install GlobalProtect vis these instructions, connecting is nearly identical on Mac or Windows PC:\n\nOpen the GlobalProtect client by selecting the icon at the top of your screen (Mac) or in the system tray (PC). (If it does not automatically appear in this place, access the client through your Finder’s Applications folder (Mac) or Start Menu (PC).)\n\nIf it is your first time connecting, you will be prompted to enter a portal address. The default portal is uwmadison.vpn.wisc.edu.\nIf you have used GlobalProtect before, you will be connected to the portal you last used. This can be changed by opening the settings menu on the top right of the client login screen.\n\n\n\n\n\nEnter your netid followed by _1 (to use your Static IP) and password (regular NetID password) and click Sign In. If you are prompted to use Duo MFA, enter the passcode from your fob/Duo Mobile app or enter “1” to receive a push on your mobile device.\n\n\n\n\n14.1.1 Troubleshooting Global Protect on Mac OSX\nIf the client never connects and just “spins”, this issue could be related to a security setting for the Mac Keychain. Properly restart the computer by clicking restart, and making sure the “Reopen windows when logging back in” is unchecked as shown here:\n\n\nOnce the computer restarts and GlobalProtect restarts upon booting back up, there will eventually be a prompt that pops up. It may ask for permission for GlobalProtect to use confidential information from the Keychain. The password should be the computer’s Admin password, or their Apple ID password. Once the password has been entered, click “Always allow”. Afterward, GlobalProtect should be able to move past the “Connecting” phase and will prompt for username and password as usual."
  },
  {
    "objectID": "globalprotect_mapping.html#connecting-to-johns-server",
    "href": "globalprotect_mapping.html#connecting-to-johns-server",
    "title": "14  Global Protect and Mapping the Network Server",
    "section": "14.2 Connecting to John’s server",
    "text": "14.2 Connecting to John’s server\n\n14.2.1 Mac OSX:\n\nAfter GlobalProtect is connected, open your Finder application: From the top utility bar Click on Go and select Connect to Server.\n\n\n\n\nEnter the server address: smb://dionysus.psych.wisc.edu/Private\n\n\n\n\nClick on the + (plus) icon to add the server name to your Favorite Servers.\nWhen you are prompted for your credentials be sure to select “Registered User”. Enter your username and password. You can also check to remember this password in your keychain, if you wish.\n\n\n\n\nClick Connect to continue"
  },
  {
    "objectID": "globalprotect_mapping.html#windows-pc",
    "href": "globalprotect_mapping.html#windows-pc",
    "title": "14  Global Protect and Mapping the Network Server",
    "section": "14.3 Windows PC:",
    "text": "14.3 Windows PC:\n\nOpen Windows explorer and click on This PC. Under the Computer tab, select Map Network Drive\n\n\n\n\nIn the dialog box, select a drive letter. For the Private drive you want to be sure to use P: as that is referenced in our analysis code.\n\n\n\n\nIn the Folder box, type the address of the drive you wish to map; i.e. \\\\dionysus.psych.wisc.edu\\private\nCheck “Connect using other credentials” and enter dionysus\\yournetid (no double slashes leading) as the username (use your actual netID), and your netID password.\nMake sure that “Reconnect at Logon” is ALSO checked and hit Finish"
  },
  {
    "objectID": "zotero.html#installation",
    "href": "zotero.html#installation",
    "title": "15  Zotero",
    "section": "15.1 Installation",
    "text": "15.1 Installation\nThere are two parts of installing Zotero. Go to https://www.zotero.org/download/ and install both the standalone, and the browser connector."
  },
  {
    "objectID": "zotero.html#registration-synchronization",
    "href": "zotero.html#registration-synchronization",
    "title": "15  Zotero",
    "section": "15.2 Registration & Synchronization",
    "text": "15.2 Registration & Synchronization\nYou’ll receive an invite to the lab Zotero group; if you already have a Zotero account, provide this to Susan to link to your invite.\nTo get the lab library into your new standalone installation, go to Preferences, and put your username or email and zotero password in where indicated. The first time you sync, it might take a few hours to load the library to your computer, so run this procedure at the end of the work day."
  },
  {
    "objectID": "zotero.html#adding-references",
    "href": "zotero.html#adding-references",
    "title": "15  Zotero",
    "section": "15.3 Adding References",
    "text": "15.3 Adding References\nBefore adding a reference, PLEASE search Zotero and make sure it’s not a duplicate!\nWe usually add references to a specific project or manuscript folder that John creates. You can find these under “Addiction Research Lab” under “Group Libraries” and highlight one that you wish to add refs to. You can also add references to the general lab library, or you can create your own personal folders under your own account (i.e. for research or classes)\n\n15.3.1 Adding a Reference Using Web Browser Plug-in\nThis is the preferred method of adding references since most websites with articles/chapters provide complete embedded metadata.\n\nOpen your standalone Zotoro (the browser connector won’t work unless it’s open) and select the project or manuscript folder you wish to add the ref to.\nGo to the webpage where the article you would like to save is located\nLook up at the browser URL box and click the page icon on the right\n\n/\n\nCheck the Zotero desktop application to confirm the reference has been saved to the desired folder in the “Addiction Research Lab” library\nIf multiple references are available on the same page, a browser connector dialogue box will open allowing you to select which of them you want to save. Useful for saving lots of references out of a page of search results!\n\n\n\n15.3.2 Manually Entering a Reference\n\nWhen using the Zotero standalone application, click the “New Item” button (green circle with the white plus sign on the top toolbar)\nSelect which type of reference you’re adding (book, journal article, etc.)\nThe new item will appear in the library and in the column on the right side\nEnter ALL available information into the appropriate fields\n\n\n\n15.3.3 Formatting\nAddiction Research Lab format for entering authors names in Zotero is: Full Last name, Full First name and Middle initial (without period)\nIMPORTANT FINAL STEP: SYNC THE LIBRARY\nAfter adding a new reference, click the green circular arrow located on the right side of the top tool bar in the desktop application The library is syncing when the arrow is spinning; do not close the desktop application until the arrow has stopped spinning Your local Zotero should now be synced with the Zotero Server so that all members will be able to access the new reference(s)"
  },
  {
    "objectID": "zotero.html#managing-pdfs-of-references",
    "href": "zotero.html#managing-pdfs-of-references",
    "title": "15  Zotero",
    "section": "15.4 Managing PDFs of References",
    "text": "15.4 Managing PDFs of References\nJohn may want references for specific manuscripts of publications saved to a certain location. If not, you save them to the generic location on the lab server:\n\nSave the .pdf file to the lab sever using the path P:\\Lit\\Articles. Note we have A-L and M-Z for author last names (because these files are so large).\nSave the file using the following naming format: Last name, First Initial, Year, a, b, c, d, etc. The letters at the end of the file name are an identifier used in the lab, which indicate the first, second, third, etc. article we have saved from that author and that publication year. Example: CurtinJ2011a for the first ref saved with that publication year; CurtinJ2011b for the second, etc."
  },
  {
    "objectID": "zotero.html#using-zotero-in-writing",
    "href": "zotero.html#using-zotero-in-writing",
    "title": "15  Zotero",
    "section": "15.5 Using Zotero in Writing",
    "text": "15.5 Using Zotero in Writing\n\n15.5.1 In Quarto\nAs of 2022, most manuscripts in our lab will be written in Quarto since it allows inline code for reproducible results. See this section for info on adding bibliographies and citations (including linked Quartro resources for further reading)\n\n\n15.5.2 In MS Word\nInsert an inline citation\n\nMake sure Zotero is running.\nIn your word document, put your cursor where you want the reference to appear, then click the Zotero menu tab.\nHit Add/Edit citation. A preferences window will come up. You can leave all of the defaults as is and just hit Okay.\n\na. Changing Citation Style will change how your citations and bibliography appear – as numbered superscripts (ie Nature) vs (Author, Year) (ie APA 6th ed), etc.\n4. A red Zotero search bar will come up and you will see a field marker {Citation} appear in your document. You can now search by author/year,or by title. You don’t have to hit enter, it starts searching as soon as you type.\n/\n\nA selection box will come up. Click the desired article (or hit enter if it’s already selected) and the name/year will turn into a blue oval in the Zotero search box. You can then start typing a new search if you want another citation in the same location:\n/\nWhen you are done adding citations and all are in blue ovals, hit enter in the Zotero search box. A green progress bar will fill the Zotero search box. When it closes your {Citation} marker will be replaced by the citations in your chosen style.\n\nGenerate a Bibliography\n\nMake sure Zotero is running.\nType “Bibliography” where you want it to appear. NOTE if this word appears in multiple places in your document, Zotero might put it in the wrong place!\nOn the Zotero menu tab click Add/Edit Bibliography.\nA window will open for you to add/remove citations. No need to change anything, just hit Okay.\nIt takes a little time for it to appear so be patient.\n\nChanging Citation/Bibliography Formats\n\nOn the Zotero menu tab, hit Document Preferences. A preferences window will come up.\nChanging “Citation Style” will change how your citations and bibliography appear – as numbered superscripts2 (ie Nature) vs (Author, Year) (ie APA 6th ed) vs bracketed citations [3] (IEEE), etc."
  },
  {
    "objectID": "zotero.html#zotero-tips",
    "href": "zotero.html#zotero-tips",
    "title": "15  Zotero",
    "section": "15.6 Zotero Tips",
    "text": "15.6 Zotero Tips\n\n15.6.1 Citation/bibliography style templates\nUse this online tool to find a template for Zotero that matches your target journal: http://editor.citationstyles.org/searchByExample/\n\n\n15.6.2 Reordering multi-citations\nClick on a place where you have multiple citations together and click Add/Edit citation. You can then drag the blue ovals around inside the Zotero search bar to change the order they are cited.\n\n\n15.6.3 Saving multiple citations in Pubmed\nIf you have a page of Pubmed search results up, you can click several articles that you want Zotero to save before hitting the “Save to Zotero” button. The dialogue box that comes up will helpfully have these same references checked for you automatically!\n\n\n15.6.4 Where to save citations from\nThe best webpage to save from is always Pubmed, as it is perfectly formatted to give Zotero all the necessary metadata. Some webpages (like Cochrane Library) are also perfectly formatted. Others are not, and Zotero will save the reference as a webpage rather than a journal article. You can tell this will happen because hovering over the Zotero button says “Save to Zotero (Web Page with Snapshot)”. So make sure it doesn’t say this when you try to save! Also, you can open PDFs directly in Chrome and use the button to try to add it, but Zotero may or may not correctly pull the metadata out into the reference. If not, you will see a PDF in your Zotero with no author/title. Right-click and hit “Retrieve Metadata for PDFs” and that should fix it. If not you’ll have to get it automatically.\nMost PDFs helpfully have a DOI (text or link) inside them which links you back to the original page (Pubmed or Journal) for the article. This is also an excellent way to get to a good place to use the Zotero Chrome plugin, as most of these DOI sources are perfectly formatted to work with Zotero.\n\n\n15.6.5 Troubleshooting Citations\nshowing first names sometimes This happens when an author has multiple variations in spelling/abbreviation of first & middle names. Correction procedure:\n\nIn Zotero, search by author.\nGo down the list of resultant citations and correct all author spellings to exact same format. Easiest way to do this is to backspace once in the last name, then click the desired suggestion that comes up when you retype the last letter of their last name. a. Note that this re-orders the results and you may need to check all of them several times to make sure you corrected all of them.\nSync Zotero.\nIn your word document, hit Refresh under Zotero menu item. Then, !important, in document preferences, change the citation style 2x (from whatever you currently use, to something else, then back to what you want).\n\n\n\n15.6.6 Empty local library\nIf you open Zotero and get the message “you are about to sync to an empty local library” there may be a database error which can happen when Zotero is shut down unexpectedly (ie, if the computer reboots itself).\n\nHit Edit -&gt; Preferences -&gt; Files and Folders -&gt; Show Data Directory. A file explorer window will open.\nClose Zotero while keeping that file explorer window open.\nYou will see several files whose names start with Zotero.squlite. If you see Zotero.sqlite and it’s very small (ie under 1000KB) it means it’s empty. (If it’s very large something else is wrong and you should stop). You should also see a file named Zotero.sqlite.1.bak which is very large (around 200KB).\nRename Zotero.sqlite to Zotero.sqlite.empty.\nCopy and paste Zotero.sqlite.1.bak and then rename it Zotero.sqlite\nReopen Zotero – database is fixed!\n\n\n\n15.6.7 Backing Up the Library\nThe Zotero library should be periodically backed up to the server in case someone screws it up. There are instructions on the Zotero website for how to accomplish this: http://libguides.northwestern.edu/content.php?pid=68444&sid=676064. The Zotero backup data folder is saved on our server in P:\\Lit\\Zotero."
  },
  {
    "objectID": "qr_code.html",
    "href": "qr_code.html",
    "title": "16  Creating QR Codes for Presentations",
    "section": "",
    "text": "Easy to make\nUse this website: https://app.qr-code-generator.com/manage\nLink to our posters and presentations page: https://arc.psych.wisc.edu/posters-presentations/\nInclude on last slide along with CREDITS"
  },
  {
    "objectID": "psychophysiology.html",
    "href": "psychophysiology.html",
    "title": "17  Psychophysiology Methods",
    "section": "",
    "text": "18 Electronics and Psychophysiology\nThis section will cover sensor preparation and placement for EMG, Skin Conductance and Heart Rate. For each of these measures, pre-participant preparation, participant preparation, sensor placement and sensor cleaning procedures are described below. There are many similarities in the preparation procedure across measures. Important differences between measures are highlighted."
  },
  {
    "objectID": "psychophysiology.html#measure-and-record-bioelectric-signals-erp-eeg-emg-hr",
    "href": "psychophysiology.html#measure-and-record-bioelectric-signals-erp-eeg-emg-hr",
    "title": "17  Psychophysiology Methods",
    "section": "19.1 Measure and record bioelectric signals (ERP, EEG, EMG, HR)",
    "text": "19.1 Measure and record bioelectric signals (ERP, EEG, EMG, HR)\n\n19.1.1 Neuroscan 64 channel Synamps 2\n\nObsolete, replaced by Synamps RT (https://compumedicsneuroscan.com/product/synamps-rt-64-channel-eeg-erp-ep-amplifier/)\n\n\n19.1.1.1 SynAmps2 Headbox Configuration:\n\n\n\nLeft lab headbox showing labeled channels for placement of Ground (GND), REF, ORB, and CRG\n\n\nSynamps2 and SynampsRT require a signal input to the REF channel to accurately calculate impedances (this was not the case with Synamps1). Therefore, we use a small sensor placed on the forehead 1cm to the side of the ground (left side in Left Lab) which is connected to REF on the headbox.\nThe two channels (REF and GND) should NOT be jumped. REF and GND have 2 entirely separate functions when it comes to calculating the impedances and recording the data, hence by jumping the two channels, you are essentially combining their functions. The GND’s role is to reject common mode noise during data recording. The REF channel is not actually needed for bipolar EMG data recording, but will not degrade the signal, and therefore should remain plugged into headbox.\nThis applies to EMG recording only. When recording with EEG the REF sensor included on the cap should be used and no additional EMG REF input is needed on the headbox.\n\n\n19.1.1.2 Neuroscap Hardware Filter Info\nIn the Synamp2 system the highpass is DC; however, if you record in AC, then a 0.05 Hz hardware highpass filter is applied to the data after front-end DC coupling. This filter is a single-pole Butterworth filter, and it’s 3dB down at 0.05. The lowpass hardware filter is also a single-pole Butterworth, 3dB down at a cutoff of 4,070 Hz. Note this is greater than the actual specified bandwidth of the device, which is 3,500 Hz (this is a pure software filter). The reason the hardware cutoff is &gt; 3,500 is because the filter effects are additive (hardware + software), so the attenuation at 3,500 Hz from the hardware filter is only 0.5dB.\nFor the Synamp1, this information was a little harder to track down. The hardware filter in AC mode is a single-pole RC highpass, 6dB down at 0.05 Hz. The Synamp manual documentation lists the upper-end of the software filter at 3000 Hz, and the filter is 9dB down at that cutoff. This suggests to me that, due to the additive filtering effects, the hardware lowpass is very close to 3000 Hz as well; unfortunately I have not yet been able to track down any documentation on it. I will keep searching, but wanted to report my findings before too long!\n\n\n19.1.1.3 Neuroscan AQUIRE software\n\nObsolete, replaces by CURRY: https://compumedicsneuroscan.com/product/curry-data-acquisition-online-processing-x/)\n\nHistorical Note: do not buy full SCAN package. You do NOT want EDIT. We use Matlab/EEGLab for data reduction. Also do NOT buy STIM, we use Matlab]\n\n\n\n\n19.1.2 Grael\n\nNeuroscan 32 channel HD EEG mobile unit: https://compumedicsneuroscan.com/product/grael-4k-psg-eeg-erp-amplifier/\nmobile i/o USB-DIO24/37 http://www.mccdaq.com/usb-data-acquisition/USB-DIO24-Series.aspx\nmobile sound card - http://us.creative.com/p/sound-blaster/sound-blaster-e5\nCustom system from James Long: http://www.jameslong.net/"
  },
  {
    "objectID": "psychophysiology.html#data-processingreduction-software",
    "href": "psychophysiology.html#data-processingreduction-software",
    "title": "17  Psychophysiology Methods",
    "section": "19.2 Data processing/reduction software",
    "text": "19.2 Data processing/reduction software\n\nMATLAB: http://www.mathworks.com/products/matlab/\nMATLAB Signal Processing Toolbox: http://www.mathworks.com/products/signal/\nEEGLab: Free download from http://www.sccn.ucsd.edu/eeglab/\nPhysBox: PhysBox: The Psychophysiology Toolbox https://arc.psych.wisc.edu/physbox/"
  },
  {
    "objectID": "psychophysiology.html#stimulus-control-software",
    "href": "psychophysiology.html#stimulus-control-software",
    "title": "17  Psychophysiology Methods",
    "section": "19.3 Stimulus Control software",
    "text": "19.3 Stimulus Control software\n\nPsychToolBox: https://github.com/jjcurtin/psychophysiology/tree/main/arc_library/PTB\nDMDX: Free download from http://www.u.arizona.edu/~kforster/dmdx/dmdx.htm"
  },
  {
    "objectID": "psychophysiology.html#io-card-for-inter-computer-communication",
    "href": "psychophysiology.html#io-card-for-inter-computer-communication",
    "title": "17  Psychophysiology Methods",
    "section": "19.4 I/O card for inter-computer communication",
    "text": "19.4 I/O card for inter-computer communication\n\nParallel digital I/O card: All of the following can be obtained from Measurement Computing (https://www.mccdaq.com/)\n\nFor desktop computer: PCI-DIO24 (https://www.mccdaq.com/pci-data-acquisition/PCI-DIO24-Series.aspx) & SCB-37 (https://www.mccdaq.com/productsearch.aspx?q=SCB-37) & C37FFS-5 Cable (https://www.mccdaq.com/productsearch.aspx?q=C37FFS-5) 2 feet long is the standard length I use. However, it is Available in 1, 2, 3, 4, 5, 10, 15, 20, 25, and 50-foot lengths on their website\nFor notebook computer: PC-CARD-DIO48 & SCB-50 & CPCC-50F-39 (see also USB option for notebooks)\n\n24-channel PCI-bus compatible, logic-level digital I/O board: https://www.mccdaq.com/pci-data-acquisition/PCI-DIO24-Series.aspx USB 24-channel Digital I/O Board with 37-Pin D-Sub Connector (for notebook): https://www.mccdaq.com/usb-data-acquisition/USB-DIO24-Series.aspx - We purchased this dio card but it is not supported currently by PTB. So we purchased the USB 1024LS instead (see below)\nUSB-1024LS-channel Digital I/O Device Connector (for notebook): http://www.mccdaq.com/usb-data-acquisition/USB-1024LS.aspx\nSignal connection box, 37-conductor, shielded: https://www.mccdaq.com/products/screw_terminal_bnc.aspx#\nCable, 37-conductor shielded, female to female molded connectors, 5 ft. long: https://www.mccdaq.com/Products/cables-adapters\nScrew terminal Adapter\n\nFor Desktops:\n\nCIO-MINI37 (https://www.mccdaq.com/productsearch.aspx?q=CIO-MINI37): This works for most applications.\nCIO-MINI37-VERT (https://www.mccdaq.com/productsearch.aspx?q=CIO-MINI37): This one has the connector configured vertically. Might be useful in some applications if you are building into a box that requires this orientation.\n\nFor notebooks:\n\nCIO-MINI50 (https://www.mccdaq.com/productsearch.aspx?q=CIO-MINI50): This works for most applications"
  },
  {
    "objectID": "psychophysiology.html#intercom-and-audio-stimulus-control",
    "href": "psychophysiology.html#intercom-and-audio-stimulus-control",
    "title": "17  Psychophysiology Methods",
    "section": "19.5 Intercom and audio stimulus control",
    "text": "19.5 Intercom and audio stimulus control\n\nMackie 1202 VLZ3 audio mixer-amplifier: http://www.mackie.com/products/vlz3series/splash.html\nMackie 802-VLZ3 8-Ch. Compact Recording/SR Mixer: http://www.amazon.com/Mackie-802-VLZ3-8-Ch-Compact-Recording/dp/B00132EJKG/ref=pd_bbs_sr_1?ie=UTF8&s=musical-instruments&qid=1239029418&sr=8-1\nSennheiser HD280Pro headphones: https://en-us.sennheiser.com/hd-280-pro\nShure Microflex MX418 D/S: http://www.shure.com/americas/products/microphones/microflex/mx412-mx418-gooseneck-microphones\nAudio Technica Cardiod Pro 44: http://www.audio-technica.com/cms/wired_mics/8ba9f72f1fc02bc5/index.html\nRadio Shack digital sound level meter (model: 33-2055): (Obsolete) https://www.amazon.com/Radio-Shack-33-099-Digital-Sound/dp/B000A1EHGW\nAcoustic Calibrator DR1-R (use with sound level meter to calibrate acoustic signal from headphones): http://www.digital-recordings.com/coupler/coupler.html\nPropoint Boundary Microphone: http://www.amazon.com/Audio-Technica-PRO44-Propoint-Boundary-Microphone/dp/B0002BBOOS/ref=sr_1_3?ie=UTF8&s=electronics&qid=1239029218&sr=8-3"
  },
  {
    "objectID": "psychophysiology.html#audio-recording",
    "href": "psychophysiology.html#audio-recording",
    "title": "17  Psychophysiology Methods",
    "section": "19.6 Audio Recording",
    "text": "19.6 Audio Recording\n\nShure Mic Mixer model M68: (Obsolete) https://pubs.shure.com/view/guide/M68/en-US.pdf\nRealistic 33-1090B PZM Pressure Zone Microphones: (discontinued) see http://www.uneeda-audio.com/pzm/pzm1.jpg for image.\nBehringer BEQ802USB Xenyx Q802USB Premium 8-Input 2-Bus Mixer ordered 5/26/2016 from http://www.bhphotovideo.com for mobile lab"
  },
  {
    "objectID": "psychophysiology.html#video-observation",
    "href": "psychophysiology.html#video-observation",
    "title": "17  Psychophysiology Methods",
    "section": "19.7 Video observation",
    "text": "19.7 Video observation\n\nPolarisUSA 1/3” B/W Brick Camera: Model BC-600B, replaced by http://polarisusa.com/pvi4?func=product&id=475\nPolarisUSA Portable Infrared Illuminator, 1.2 AMP Power Supply Included: http://www.polarisusa.com/product/46/IR-TILE.html\nPolarisUSA 12V DC Power Supply: http://polarisusa.com/product/1352/ps-12v-1a\n6” Camera Stand: http://polarisusa.com/pvi4?func=product&id=604\nBlack CCTV Monitor: http://www.lcdracks.com/monitors/LYNX/M-Pro-CCTV-19.php"
  },
  {
    "objectID": "psychophysiology.html#handheld-impedance-meter-for-erpeeg-only",
    "href": "psychophysiology.html#handheld-impedance-meter-for-erpeeg-only",
    "title": "17  Psychophysiology Methods",
    "section": "19.8 Handheld impedance meter (for ERP/EEG only)",
    "text": "19.8 Handheld impedance meter (for ERP/EEG only)\n\nPrep-Check electrode impedance meter (EIM 105-30Hz): [ http://www.general-devices.com/eim105.htm Obsolete, replaced by https://www.biopac.com/product/electrode-impedance-checker/"
  },
  {
    "objectID": "psychophysiology.html#erpeeg-electro-caps",
    "href": "psychophysiology.html#erpeeg-electro-caps",
    "title": "17  Psychophysiology Methods",
    "section": "19.9 ERP/EEG electro caps",
    "text": "19.9 ERP/EEG electro caps\n\nElectro-cap International: http://www.electro-cap.com/\n\nWe use custom cap configurations. See the Order form (P:\\Documentation\\Hardware\\EEGCaps&Connectors\\CustomCapOrderForm.pdf) and Pinouts P:\\ Documentation \\Hardware\\EEGCaps&Connectors\\ECICapPinout.pdf)\n\nElectrode Board Adapter (E2S): http://electro-cap.com/index.cfm/pricing/"
  },
  {
    "objectID": "psychophysiology.html#agagcl-sensors",
    "href": "psychophysiology.html#agagcl-sensors",
    "title": "17  Psychophysiology Methods",
    "section": "19.10 Ag/AgCl sensors",
    "text": "19.10 Ag/AgCl sensors\n\nLarge Ag/AgCl electrode. TDE-022-Y-ZZ-S Electrode, 8mm, and 48in lead length: http://www.discountdisposables.com/electrodes/reusable-electrodes/tde-022-y-zz-s-electrode-8mm.html\nSmall Ag/AgCl electrode; TDE-023-Y-ZZ-S Electrode, 4mm, and 48in lead length: http://www.discountdisposables.com/electrodes/reusable-electrodes/tde-023-y-zz-s-electrode-4mm.html"
  },
  {
    "objectID": "psychophysiology.html#shock-electrodes",
    "href": "psychophysiology.html#shock-electrodes",
    "title": "17  Psychophysiology Methods",
    "section": "19.11 Shock electrodes",
    "text": "19.11 Shock electrodes\n\nAs of 12/2016, we currently have 2 older sets of non-disconnectable and 2 sets (one at CRU) of disconnectable electrodes.\n\nNone of these three are shielded/grounded.\nThe newer types currently in use are:\n1. in left lab are grounded and shielded, non-disconnectable. 2. in right lab are grounded and shielded, disconnectable. 3. in CRU mobile lab, are grounded and shielded, disconnectable.\nThe shock electrode wires act like a big antenna, so over time we have made multiple adjustments to try and reduce the interference from them: * All our new cables are now shielded and grounded to the i/o box. * The wires should be shielded as far up to the electrodes as possible. Any gap on the shielding increases antenna interference again. If they are to be disconnectable, shielding can terminate at the disconnect, but disconnectable ones will always have more interference than non-disconnectable. * The unshielded portion of the wires (whether or not disconnectable) should be as short as possible. Ideally 3-4”, just enough to allow them to be connected to the two fingers of various size hands. * The cable itself should be as short as possible, because the length alone is a factor in the strength of the antenna being formed. Right now about 16 feet seems to be working well (left lab)."
  },
  {
    "objectID": "psychophysiology.html#miscellaneous-equipment",
    "href": "psychophysiology.html#miscellaneous-equipment",
    "title": "17  Psychophysiology Methods",
    "section": "19.12 Miscellaneous equipment",
    "text": "19.12 Miscellaneous equipment\n\n2 Port 250 MHz VGA Video Splitter (ST122L): http://www.startech.com/Product/ItemDetail.aspx?productid=ST122L&c=US"
  },
  {
    "objectID": "psychophysiology.html#computers",
    "href": "psychophysiology.html#computers",
    "title": "17  Psychophysiology Methods",
    "section": "19.13 Computers",
    "text": "19.13 Computers\n\n2 computers, one for data acquisition, one for stimulus control"
  },
  {
    "objectID": "psychophysiology.html#sound-cards",
    "href": "psychophysiology.html#sound-cards",
    "title": "17  Psychophysiology Methods",
    "section": "19.14 Sound Cards",
    "text": "19.14 Sound Cards\n\n185L: Creative Sound Blaster X-Fi Titanium PCI Express Sound Card: (Obsolete)\n185R: Creative Sound Blaster ZxR PCIe Audiophile Grade Gaming Sound Card http://us.creative.com/p/sound-blaster/sound-blaster-zxr\nSound Blaster E5 external sound card (for notebook): http://us.creative.com/p/sound-blaster/sound-blaster-e5"
  },
  {
    "objectID": "psychophysiology.html#monitors",
    "href": "psychophysiology.html#monitors",
    "title": "17  Psychophysiology Methods",
    "section": "19.15 Monitors",
    "text": "19.15 Monitors\n\n2 LCD flat panel for experimenter to view physiology and experimental stimuli\n1 large CRT for participant display\nOptional: Support to mount LCDs on wall to save desk space"
  },
  {
    "objectID": "psychophysiology.html#psychophysiology-supplies",
    "href": "psychophysiology.html#psychophysiology-supplies",
    "title": "17  Psychophysiology Methods",
    "section": "19.16 Psychophysiology supplies",
    "text": "19.16 Psychophysiology supplies\nSee Psychophysiology supplies under P:\\\\private\\ Documentation \\Supplies\\CommonLabSupplies.docx"
  },
  {
    "objectID": "psychophysiology.html#psychophysiology-peripherals-diagrams",
    "href": "psychophysiology.html#psychophysiology-peripherals-diagrams",
    "title": "17  Psychophysiology Methods",
    "section": "19.17 Psychophysiology Peripherals Diagrams",
    "text": "19.17 Psychophysiology Peripherals Diagrams\n\nRedel Connector\n\nFixed Response Delay Board\nPhoto Sensor\nResponse Button\nVoltage Divider"
  },
  {
    "objectID": "psychophysiology.html#calibrate-white-noise-startle-probes-for-hd280pro",
    "href": "psychophysiology.html#calibrate-white-noise-startle-probes-for-hd280pro",
    "title": "17  Psychophysiology Methods",
    "section": "20.1 Calibrate White Noise Startle Probes for HD280Pro",
    "text": "20.1 Calibrate White Noise Startle Probes for HD280Pro\nRecord the decibels before and after calibration in a Startle Probe Calibration Log .xlsx file\nThese instructions are for the sound meter, the bigger one, that is housed in a suitcase, and has a headphone holder.\nBring this sound meter into the room where participants receive startle probes.\nOn the Mackie audio mixer, verify that the sub mix are is the indent/U and the main mix, which controls RA speaker volume, is turned all the way to the right/max. Verify that the computer volume never changes after initial calibration of the sound probe.\n\nPull the meter out of the suitcase and slip the metal sleeve over the meter:\n\nThe circular end of the meter should slip into a round opening at the top of the metal sleeve.\nTurn the meter dials as follows:\n\n\n\n\nThe db range should be set to 100.\n\n\n\n\n\nThe Batt dial should be set to A on the slow side.\n\n\n\n\n\nThe frequency dial should be set to 250.\n\n\n\nPull the Batt dial out- (this turns the device on).\nLoosen the wing nuts until you can move the metal arm on the top of the metal sleeve.\nSlip one headphone in between the metal arm, and metal sleeve. The headphone should surround the round opening at the top of the metal sleeve:\n\nTighten the wing nuts so that the headphone cannot slip out of this position however do NOT tighten the wing nuts such that the cushion on the headphone is pressed. The headphone cushion should be fully expanded as in the picture.\nTurn on the computer that generates the startle (in both labs, it is the computer that is on the right), and open up DMDX or Matlab depending on how you control your stimulus presentation.\nIf using DMDX, click browse, and follow this file path: local/calibrate/CalibrateLong.rtf Select the CalibrateLong.rtf file, and hit run.\nIf using Matlab, type “CalibrateWhiteNoise” and hit Enter.\nNow, hit the space bar to initiate the long probe.\nMove quickly back to the sound meter, and check where the decibel needle is pointing. The goal is to get the needle to point to 2.\nIf the needle is not pointing towards 2, you will need to adjust the 5-6 gain dial on the audio mixer.\nCheck both headphones (left and right) and make sure both are outputting at 2.\n\nFor DMDX: If the probe ends before you can adjust the needle accurately enough, hit escape to get out of the file, do not save the data, and run the long startle probe calibration file again.\nFor Matlab: If the probe ends before you can adjust the needle accurately enough, hit “enter” and type “CalibrateWhiteNoise” and hit enter again.\nOnce you are finished Close DMDX or Matlab and shut down the computer.\nMake sure to turn the sound meter off by pushing the batt dial back in. (if you do not- the battery will die)\nReturn the sound meter to its carrying case, and then to the shop."
  },
  {
    "objectID": "psychophysiology.html#calibrate-white-noise-startle-probes-for-er-4s-ear-insert-earphones",
    "href": "psychophysiology.html#calibrate-white-noise-startle-probes-for-er-4s-ear-insert-earphones",
    "title": "17  Psychophysiology Methods",
    "section": "20.2 Calibrate White Noise Startle Probes for ER-4S Ear Insert Earphones",
    "text": "20.2 Calibrate White Noise Startle Probes for ER-4S Ear Insert Earphones\nThe ER-4S has a known voltage input to sound intensity output function. This function can be used to calibrate the intensity of the startle probe, etc. This function is:\nIntensity (dB) = 108 + 20 log10(voltage [in V])\nVoltage should be measured in AC V using RMS (see note below on modifications present in Curtin Lab)\nTo measure this voltage you will need to build an adapter that will allow you to insert volt meter test point probes (black and red probes attached to meter) into a wire connected between your sound card and the ER-4S earphones. It is important that the earphones are connected when making this measurement b/c their presence in the circuit will affect the voltage measured. The easiest option is to splice two wires into a cable with male and female mini (1/8 inch) phono plugs. Splice one wire onto the ground/shield and the second to either of the audio channels (left and right ear should contain the same signal). Plug the male connector into the sound card, plug the earphones into the female end and alligator clip the meter probes onto the two wires you spliced in.\nYou should produce the sound with the software and wav file you intend to use for sound presentation b/c they both will affect the intensity of the sound. I have created two calibration scripts for DMDX:\n\nA long probe script (32s probe for calibration)\nA short probe script (standard 50ms probe to demo the probe if desired)\n\nThe script uses a short (50ms) and long (32 s) wav file for white noise. These must be in the same folder as the script. The long file was constructed with the same parameters as the short file and presents at the same intensity. If you calibrate with the long file, you should obviously use this short wav file in your experiments.\nHere is a quick reference table for typical values to convert from observed voltage to dB. Intermediate values can be determined using the formula provided above.\n\n\n\n\n\n\n\nVoltage Input (V)\nSound Intensity Output (dB)\n\n\n\n\n.2\n94.0\n\n\n.3\n97.5\n\n\n.4\n100.0\n\n\n.5\n[.35V*]\n\n\n.6\n104.0\n\n\n.7\n105.0\n\n\n\n*IMPORTANT NOTE FOR CURTIN LAB. In our lab, our voltmeter is not RMS. 102DB should measure .5V RMS but on our meter it measures .35V. Calibrate to .35V using the 2V range setting"
  },
  {
    "objectID": "psychophysiology.html#testing-acoustic-startle-probes",
    "href": "psychophysiology.html#testing-acoustic-startle-probes",
    "title": "17  Psychophysiology Methods",
    "section": "20.3 Testing Acoustic Startle Probes",
    "text": "20.3 Testing Acoustic Startle Probes\n[TestWhiteNoise.m](https://raw.githubusercontent.com/jjcurtin/psychophysiology/main/arc_library/PTB/TestWhiteNoise.m) is used to test acoustic startle probe presentation and timing relative to event code. TestWhiteNoise presents 10 white noise probes (WNProbe.wav) separated by 2s. Each probe is marked with an event code of 100. White noise onset should occur a short, fixed interval after event code if system is working properly.\n\n20.3.1 Conducting the Test\n\nOpen Matlab on Stimulus Control computer\nType TestWhiteNoise at Matlab command prompt. Default is to analyze output in EEGLab. Type TestWhiteNoise(false) if no analysis is necessary.\nOpen Neuroscan and select setup file that records probe channel and uses an event code hold value of 0 (e.g., NoiseTest_SynAmps1.ast; NoiseTest_SynAmps2.ast)\nView Neuroscan data and start saving. NOTE: Save to server if you want immediate access for analysis.\nPress any key on Stimulus Control computer to begin test\nDon’t forget to stop saving in SCAN once probes are complete!\n\n\n\n20.3.2 Analysis of Output\n\nAfter data are collected, Matlab will display a dialog box to select data file and path\nNext input data type (16 bit/synamps 1 or 32 bit/symamps 2)\nScript will generate a plot of the 10 probe administrations\nProbe onset should be within 4 ms of 0 and consistent\nProbe offset should be near 50ms and consistent\nThere should be no dead spots in signal\n\n\n\n20.3.3 Troubleshooting\nIf there are issues (i.e. no sound coming from headphones) please check to see if the audio mixer is configured correctly by going to the Configuration document in P:\\Documentation\\Hardware\\MackieMixer.\nAlso you can check to see if the sound card is configured correctly by checking the config document here: P:\\Documentation\\Hardware\\SoundCards"
  },
  {
    "objectID": "psychophysiology.html#testing-response-time-accuracy",
    "href": "psychophysiology.html#testing-response-time-accuracy",
    "title": "17  Psychophysiology Methods",
    "section": "20.4 Testing Response Time Accuracy",
    "text": "20.4 Testing Response Time Accuracy\nTestResponseTime.m is used to verify that behavioral response input time is accurate. To be used with a response box that simulates participant input. When box is triggered, it produces an input exactly 434ms later. The script completes 200 presentations of this simulated input. This can be changed by passing a different input such as “TestResponseTime (365)”\n\n20.4.1 Performing the Test\n\nPlacement of banana plugs on the Breakout Box (see diagram in P:\\Documentation\\Hardware\\IO if needed). The cord from the breakout box is the grey one coming in right center, over the VGA Splitter\nRefer to the IO Card Pinout diagram (P:\\Documentation\\Hardware\\IO) if needed:\n\nTurn off the stimulus computer.\nResponse box BLACK plug should be connected to GND (pin 19).\nGREEN plug should be connected to PortB output B0 (pin 10)\nWHITE plug should be connected to PortA input A1 (pin 36). This assumes testing is on line 1 (negative).\nRED should be connected to +5v (pin 18)\n\n\nTurn on the computer\nStart Matlab and type TestResponseTime\nPress any key on Stimulus Control computer to initiate test\n\nWhen unplugging the box, first turn off the computer, then be sure to unplug the BLACK plug (GND) last.\n\n\n20.4.2 Interpreting Test Results\nAfter data are collected, Matlab will display stats and a histogram\nResponses should be constant with no bias (within ~ 5ms)."
  },
  {
    "objectID": "psychophysiology.html#testing-neuroscan-event-codes",
    "href": "psychophysiology.html#testing-neuroscan-event-codes",
    "title": "17  Psychophysiology Methods",
    "section": "20.5 Testing Neuroscan Event Codes",
    "text": "20.5 Testing Neuroscan Event Codes\nTestEventCodes.m is used to output a series of event codes from the Stimulus Control computer to the Physiology computer. This test script will also determine if the time between event codes appears to be accurate (as recorded by the Stimulus Control computer).\n\n20.5.1 Conducting the Test\n\nOpen Matlab on the Stimulus Control computer\nOpen Neuroscan and select any setup file that uses an event code hold value of 0 (e.g., TestSynamp1.ast synamp1; synamps2)\nStart viewing data in Neuroscan\n(Optional) Start saving data in Neuroscan. This will allow you to do a more rigorous test of event code timing as recorded on the Physiology computer\nType TestEventCodes at Matlab command line. NOTE: By default TestEventCodes outputs a series of 10 event codes [1:5, 101:105]. However, you can output a series of any length of any values by providing EventCodes as an argument. e.g., TestEventCodes([1 11 101 151 201]).\n\n\n\n20.5.2 Interpreting the Output\n\nYou should see the appropriate event codes on the bottom of the Neuroscan screen\nTestEventCodes will return the mean time between events. It should be 2.000s\nIf you omit the semi-colon when you type TestEventCodes, it will also return the time between each event"
  },
  {
    "objectID": "psychophysiology.html#testing-display-presentation-timing",
    "href": "psychophysiology.html#testing-display-presentation-timing",
    "title": "17  Psychophysiology Methods",
    "section": "20.6 Testing Display Presentation Timing",
    "text": "20.6 Testing Display Presentation Timing\n\n20.6.1 General\nTestDisplay.m TestOutput.mis used to verify that display timing is accurate and synched to event codes. The script completes 100 presentations of a full screen white “box” with black ITIs. The ITI is a function of the refresh rate and the FlipFrame argument to the function but the default is appropriate for almost all use. The script will mark each trial onset with an event code (1) and report statistics on trial onset timing as monitored by Psychtoolbox. Obvious tearing of the image will indicate serious timing problems. Significant departure from expected ITI time and or large SD in observe ITIs will also indicate a problem. If you use a photoresistor, you can verify that trial onset is synched with event codes.\nNOTE: Older video drivers can throw errors due to the split monitor signal. If this is the case, unhook the splitter so the participant monitor is directly connected to the matlab computer. Run the test, confirm the results are good, then reconnect the splitter.\n\n\n20.6.2 Placement of photoresistor\n\n\n\n20.6.3 To record event codes and photoresistor output\n\nUsing suction cup, place the end of the photoresistor on the upper left corner of the display to be tested. Get as close to the top and left edges as possible.\nConnect to headbox for your specific physiology equipment following the instructions below\nTurn on the photoresistor by flipping the toggle switch on the black box. Connections Instructions\n\n\n20.6.3.1 For Grael EEG\n\nConnect photoresistor leads to BP40 (or whatever channel ORB is set to in your set up file) on the Grael EEG box. Make sure to connect the BLUE lead to the NEGATIVE channel and the WHITE lead to the POSITIVE channel.\n\n\n\n20.6.3.2 For Synamps II\n\nConnect photoresistor leads to BP2 (or whatever channel ORB is set to in your set up file) on the neuroscan box. Make sure to connect the BLUE lead to the NEGATIVE channel and the WHITE lead to the POSITIVE channel.\n\n\n\n20.6.3.3 For Synamps I\n\nConnect photoresistor leads to BP32 on the neuroscan box. Make sure to connect the BLUE lead to the NEGATIVE channel and the WHITE lead to the POSITIVE channel.\n\n\n\n20.6.3.4 For James Long\n\nConnect photoresistor BNC to BNC input in control room.\n\n\n\n\n20.6.4 Performing the Test on Synamps amplifier (most of ARL)\n\nStart Matlab and type TestDisplay. Wait for the “press any key” prompt to come up.\nStart Neuroscan and select a setup file with an event hold value of 0 and a channel to record output from the photoresistor. Example files can be used: synamps2TestDisplay.ast.\nPress acquire and begin recording. You will be prompted to save the file; save locally in the Matlab-accessible folder\nPress any key on Stimulus Control computer to initiate test\nWhen Matlab prompts that the test has ended, stop data collection.\nMatlab script will automatically ask you to browse to the saved file, and then display the data\n\n\n\n20.6.5 Performing the Test on Grael EEG amplifier (mobile lab)\n\nStart Matlab and type TestDisplay(20,1,0,1). Wait for the “press any key” prompt to come up.\nStart Curry and select a setup file with an event hold value of 0 and a channel to record output from the photoresistor. Example files can be used:(see Kaye2 for example)\nSelect your save path; save locally in the Matlab-accessible folder (or copy to server after recording to allow matlab to access file).\nPress Play to connect to amplifier and press record and begin recording.\nPress any key on Stimulus Control computer to initiate test\nWhen Matlab prompts that the test has ended, stop data collection (and move Curry *.dat file to server if matlab doesn’t have access to Curry computer).\nMatlab script will automatically ask you to browse to the saved file, and then display the data ### Performing the Test on James Long Note this section may be outdated and if so should be removed\nStart SnapMaster after selecting a setup file with an event channel\nDisplay and save data file locally with Neuroscan and SnapMaster\nMove saved data file from local drive to server\nSelect file from server (Matlab script will automatically display data) Interpreting Test Results Zoom in near zero on the x axis. Onset of each white screen should be consistent (each voltage line). There should be no severe deviations or dead spots in the signal\n\n\nDisplayTest.m Output"
  },
  {
    "objectID": "psychophysiology.html#testing-io-output",
    "href": "psychophysiology.html#testing-io-output",
    "title": "17  Psychophysiology Methods",
    "section": "20.7 Testing IO Output",
    "text": "20.7 Testing IO Output\n[TestOutput.m]https://raw.githubusercontent.com/jjcurtin/psychophysiology/main/hardware/hardware_testing/TestOutput.m) is used to test a single digital output from Stimulus Control computer. This can be on either port B or C (the two output ports). This can be used to test event codes to neuroscan or to test TTLs on port C (for external devices such as shocker).\nIn Matlab type TestOutput(Output, Port), where output is 8-bit integer (0-255) and Port is either ‘B’ or ‘C’. ‘B’ is default if omitted. e.g., TestOutput(100,'B')"
  },
  {
    "objectID": "psychophysiology.html#channel-caps",
    "href": "psychophysiology.html#channel-caps",
    "title": "17  Psychophysiology Methods",
    "section": "21.1 32 Channel Caps",
    "text": "21.1 32 Channel Caps\n\nChannel Assignment\nCustom 32Ch Cap Order Form\n32 Channel Cap Diagram\n32 Channel Cap Connector Diagram\n32 Channel Pinout\nSynamps2 Pinout"
  },
  {
    "objectID": "psychophysiology.html#channel-caps-1",
    "href": "psychophysiology.html#channel-caps-1",
    "title": "17  Psychophysiology Methods",
    "section": "21.2 64 Channel Caps",
    "text": "21.2 64 Channel Caps\n\n\n\n\n64 Channel Cap Diagram\n\n\nCustom 32Ch Cap Order Form\n64 Channel Pinout"
  },
  {
    "objectID": "psychophysiology.html#sensor-placement-videos",
    "href": "psychophysiology.html#sensor-placement-videos",
    "title": "17  Psychophysiology Methods",
    "section": "22.1 Sensor Placement Videos",
    "text": "22.1 Sensor Placement Videos\nSensor Prep\nCorrugator/Orbicularis\nSkin Conductance\nSensor Cleaning"
  },
  {
    "objectID": "psychophysiology.html#pre-participant-preparation",
    "href": "psychophysiology.html#pre-participant-preparation",
    "title": "17  Psychophysiology Methods",
    "section": "22.2 Pre-participant preparation",
    "text": "22.2 Pre-participant preparation\nFor all measures, prior to the arrival of the participant you should:\n\nFill “gel applicator” with gel\n\nLocate a gel applicator body and applicator tip (in kitchen room on sink counter in organizer)\nPrior to attaching the tip, insert the applicator body into the conductive gel in the Tupperware container with plunger completed depressed. Slowly withdraw the plunger until the applicator body is almost full (for EEG) or about 2mL (for EMG only). This may take a few attempts.\nWipe off the excess\nAttach applicator tip\n\nCut sensor collars\n\nThe EMG sensor collars are cut in order to allow them to be placed closer together and closer to the site of EMG activity. There are two different cutting procedures: one for obicularis and corrugator and a second for zygomatic.\nFor obicularis and corrugator, we cut both the top and insides of the collars to allow the sensors to be placed close together and near either the eyelid (for obicularis) or the eyebrow (for corrugator) \nFor zygomatic, we cut only the inside of the sensor collars to allow the sensors to be placed close together. \n\nPlace sensor collars on sensor cups.\n\n\nThere are two sizes of sensors, depending upon the measure used.\n\nThe miniature sensors are used for facial EMG (obicularis, corrugator and zygomatic)\nThe standard sensors are used for skin conductance, heart rate and the ground sensor.\n\nLocate the appropriate size sensor collar and affix to the sensor such that the hole in the collar fits exactly around the sensor cup surface and the tab is in line with the sensor lead (wire). Make certain that the collar is securely attached by rubbing firmly with your thumb."
  },
  {
    "objectID": "psychophysiology.html#participant-preparation",
    "href": "psychophysiology.html#participant-preparation",
    "title": "17  Psychophysiology Methods",
    "section": "22.3 Participant Preparation",
    "text": "22.3 Participant Preparation\n\nHave the participant wash their hands and face with warm soapy water to remove make-up and dirt/oils. Make certain that they thoroughly dry hands and face afterwards. Explain to them that this is to allow for better measurement of the physiological signals that we are collecting.\nPrepare each site to reduce sensor impedance for all measures except skin conductance. No preparation is done for the skin conductance site. The preparation is performed in two steps. Make certain that you explain each step to the participant prior to beginning.\n\nClean the area with an alcohol prep pad. Make certain that you have the participant close their eyes if you are anywhere near the eye. Be gentle, but firm with cleaning.\n\nClean the area with the exfoliating gel (Nu-prep). Put a small dollop on Nu-prep on the end of a gauze pad. Rub the gauze pad over the placement site. If possible, rub in multiple directions to further reduce impedance. Again, be firm but gentle. Be particularly gentle with the obicularis site under the eye. After rubbing the gel into the site, use a clean portion of the gauze pad to remove excess gel from the skin."
  },
  {
    "objectID": "psychophysiology.html#general-information-on-sensor-placement",
    "href": "psychophysiology.html#general-information-on-sensor-placement",
    "title": "17  Psychophysiology Methods",
    "section": "22.4 General information on Sensor Placement",
    "text": "22.4 General information on Sensor Placement\nPrior to the application of each sensor, you will need to fill it with gel. All of the measures use the same conductive gel (in the large Tupperware container) except for skin conductance. It is VERY IMPORTANT that you do not use the conductive gel for the skin conductance sensors. This measure has its own gel.\nFor all sensors but skin conductance, you will fill the sensor cup evenly with gel from the gel applicator such that the gel slightly overfills the cup. Do not overfill too much as it will interfere with the sensor collar adhering to the participant. It is VERY IMPORTANT that you do not touch the sensor cup surface with the gel applicator tip. This will destroy the Ag-AgCl coating.\nFor skin conductance, you will fill the sensor cup with gel directly from the skin conductance gel bottle. You want the gel to completely fill the sensor cup but not overfill at all."
  },
  {
    "objectID": "psychophysiology.html#sensor-locations",
    "href": "psychophysiology.html#sensor-locations",
    "title": "17  Psychophysiology Methods",
    "section": "22.5 Sensor Locations",
    "text": "22.5 Sensor Locations\nSensor location and procedures are described below for each measure separately. When placing sensors on the face, position the sensor leads back behind the ear after placement to avoid the lead dangling in the face of the participant.\n\n22.5.1 Obicularis Placement (miniature sensors)\n\nPrior to attaching these sensors inform the participant that the sensors will feel a bit funny under their eye and may make their eye blink and water for a few moments. Tell them that they will get used to the feeling within a few minutes.\nTell the participant to look directly forward and up. Place the first sensor under the eye and directly in line with the pupil. You should place the sensor such that the collar top fits right into the crease under the eyelid.\n\nPlace the second sensor directly next to the first and to the outside (and slightly superior if possible) of the first sensor such that the collars just touch. Again, this should place the top of the collar right into the crease under the eye.\nPlug end of sensor leads into the headbox. Place the first sensor lead into the – (bottom) channel and the second into the + (top) channel.\n\n\n\n22.5.2 Obicularis Placement with EEG Cap VEOG, Ground, and Reference Sensors\n\nFollow the instructions above to place the obicularis sensors on the eye closest to the headbox (location therefore differs depending on which lab, see images below)\nPlace the VEOG sensors on the other eye. Place the lower sensor directly under the eye and in line with the pupil, and the upper sensor directly above that, immediately above the eyebrow.\nPlace the large Ground sensor about 1” from the bridge of the nose, slightly towards the VEOG side. Be careful it will not be rubbed or disloged by the edge of the EEG cap.\nPlace the smaller Reference sensor next to the Ground sensor, slightly towards the orbicularis side. Be careful it will not be rubbed or disloged by the edge of the EEG cap.\n\nVEOG placement with headbox on participant’s left: \nVEOG placement with headbox on participant’s right:\n\n\n\n22.5.3 Corrugator placement (miniature sensors)\n\nThe first sensor is placed above the eyebrow and directly in line with inside corner of the eye. You should place this sensor as close to the eyebrow as possible.\nThe second sensor is placed directly next to the first sensor and to the outside of the eye.\n\nPlug end of sensor leads into the headbox. Place the first sensor lead into the – (bottom) channel and the second into the + (top) channel.\n\n\n\n22.5.4 Zygomatic placement (miniature sensors)\n\nDraw an imaginary line between the corner of the mouth and the indentation at the top of the ear. Place the first sensor directly in the center of this imaginary line.\nPlace the second sensor directly next to this sensor and closer to mouth on this imaginary line.\nPlug end of sensor leads into the headbox. Place the first sensor lead into the – (bottom) channel and the second into the + (top) channel.\n\n\n\n22.5.5 Heart Rate placement (standard sensors)\n\nYou will place one sensor on the inside of each forearm. The exact location does not have to be precise. However, you should make certain not to place the sensor directly on top of a vein or on a hairy section of the arm.\nPlug end of sensor leads into the headbox. Place the sensor lead on the left are into the – (bottom) channel and the lead on the right arm into the + (top) channel.\n\n\n\n22.5.6 Skin Conductance placement (standard sensors w/ special gel)\n\nPrior to attaching these sensors, you will need to place a second set of sensor collars directly on the palm of the hand. This is to make certain that the surface area of the contact remains constant (and is not affected by smearing gel under the collar).\nYou will place these collars on the fleshy part of the palm under the pinky. Place the two sensors vertically on the palm with the outer edges of the collars just touching. After placing each collar, remove the adhesive covering.\nYou will place each sensor directly on top of these collars. It is very important that you line up the collars exactly. First align one edge and then very carefully align sides while placing.\nIf the sensor appears to be insecurely attached, you can wrap tape around the sensor cup to secure more firmly to the palm.\nPlug end of sensor leads into the extensions hanging out of the skin conductance amplifier (into where it says subject input). Place the top sensor lead into the top channel and the bottom sensor into the bottom channel.\n\n\n\n22.5.7 Ground sensor placement (standard sensor)\n\nYou will attach a ground sensor in the center of the participant’s forehead. Attach this sensor such that the sensor lead is pointing up and back toward the participants ear to avoid the lead dangling in the participants face.\nPlug end of sensor leads into the ground channel on the headbox."
  },
  {
    "objectID": "psychophysiology.html#sensor-removal-and-cleaning",
    "href": "psychophysiology.html#sensor-removal-and-cleaning",
    "title": "17  Psychophysiology Methods",
    "section": "22.6 Sensor Removal and Cleaning",
    "text": "22.6 Sensor Removal and Cleaning\n\nDisconnect each sensor lead from the headbox and drape to the side of the participant so that you do not step on the leads.\nCarefully remove the electrodes from the participant. For the facial EMG sensors, it is often best to place one finger on the participants face directly next to the sensor to avoid the skin pulling while removing the sensor. It is very important that you do not pull on the sensor leads. Pull on the sensor collar tabs to remove.\nBring all of the sensors (and the gel applicator) to the sink in the recovery rom, and follow the cleaning instructions."
  },
  {
    "objectID": "psychophysiology.html#prepping-startle-quick-reference",
    "href": "psychophysiology.html#prepping-startle-quick-reference",
    "title": "17  Psychophysiology Methods",
    "section": "22.7 Prepping Startle: Quick Reference",
    "text": "22.7 Prepping Startle: Quick Reference\nThese instructions refer to Corrugator/Orbicularis (miniature sensors) and Ground placement (large sensors)\n\nClean all sites with alcohol prep pad.\nClean all sites with NuPrep (exfoliant).\nFill sensors with gel, and apply. (you should be talking to the participant and making them comfortable during this time). Sensors should already have collars on them and orb collars should already be cut.\nPlug electrodes into headbox\nCheck impedances from the hookup.\n\nAll impedances should be less than 10. Re-prep if necessary.\nVerify that signal to noise ratio is adequate.\nConfirm that you can see eyeblinks on the orb channel."
  },
  {
    "objectID": "psychophysiology.html#checking-sensor-impedance",
    "href": "psychophysiology.html#checking-sensor-impedance",
    "title": "17  Psychophysiology Methods",
    "section": "22.8 Checking Sensor Impedance",
    "text": "22.8 Checking Sensor Impedance\n\nOpen Neuroscan and go into File&gt;LoadSetup&gt; and then load C:\\Local\\LocalLabema1\\Labema1_Screen.ast\nClick “Aqusition” at the top of the screen and then click “Impedences” Verify that all impedences are below 10 microvolts.\nCheck for excessive signal noise by selecting the small green arrow on the toolbar to view the actual EEG signal. Ask participant to blink twice very hard to check recording.\nMake sure that the scale in the lower right corner is at -512 microvolts and 1 second. (Correct by pressing up up/down left/right arrows on keyboard)"
  },
  {
    "objectID": "psychophysiology.html#eeg-cap-cleaning-instructions",
    "href": "psychophysiology.html#eeg-cap-cleaning-instructions",
    "title": "17  Psychophysiology Methods",
    "section": "23.1 EEG Cap Cleaning Instructions",
    "text": "23.1 EEG Cap Cleaning Instructions\n\nRemove the sticky collars and any tape from the external sensors.\nFill the cap cleaning container (clear rectangular tupperware) with warm soapy water.\nLet the cap soak in the warm soapy water for a few minutes and stir around to clean.\nHold each of the external sensors, and the inside cup of each of the cap sensors, under the water stream from the faucet to remove gel.\nUse the toothbrush or “Orange Sticks” in the drawer to scrub out remaining gel. Check each sensor to make sure that all gel is removed for the inside cup.\nClean the outside of all sensors with water from faucet (top of cap)\nOnce you are confident that all the gel is removed from the sensors, place the cap in the disinfectant underneath the sink for at least 10 minutes. It is important not to leave the cap soaking for more than 30 minutes or it will begin to deteriorate.\nWhile you are waiting, clean the gel applicators. Shoot all gel from applicator in the trash or down the sink. Dispose of the blunt tip in trash. Fill applicator with water and shoot through top a few times to make sure it is cleaned inside.\nRemove EEG cap from disinfectant and rinse. Fill the tupperware full of clean water and rinse repeatedly (with fresh water) until no more bubbles appear. This is to make certain that all disinfectant is clean from the cap or else it will smell and deteriorate.\nHang cap from hook to right of sink with the connector end carefully tucked on top where it can’t get dripped on.\n\nIMPORTANT NOTE: Cleaning the cap carefully is VERY important. The caps cost close to $1000 each. You must make certain that ALL gel is out of the sensor cups. Even a minute amount of residual gell will dramatically reduce the life of the cap and the integrity of subsequent data collection. Also, never let the end connector get wet."
  },
  {
    "objectID": "psychophysiology.html#sensor-removal-and-cleaning-1",
    "href": "psychophysiology.html#sensor-removal-and-cleaning-1",
    "title": "17  Psychophysiology Methods",
    "section": "23.2 Sensor Removal and Cleaning",
    "text": "23.2 Sensor Removal and Cleaning\n\nRemove sensor sticker collars from each sensor. Do not pull on the leads; hold by the sensor cup and the tab on the sensor collar.\nIf you can’t start cleaning immediately, it’s okay to soak the cup ends in clean water for 5-10 minutes until you are able to start. This makes it easier to clean later by preventing the gel from drying out. It’s okay to put them in clean water with the EEG cap, but do NOT put the sensors in soapy water. Be sure the plug ends stay dry!\nPlace each sensor cup directly under the jet stream from the faucet. Make certain that the end of the sensor leads do not get wet. Hold the sensor close to the bottom of the sink to reduce splashing. Move the orientation of the sensor around relative to the jet stream to allow the water to hit the sensor cup from different angles. Do this for 10-15 seconds.\nRemove the sensor from the water and blow firmly on the cup to remove the water. A clean sensor will appear matte-dry and not at all shiny. Any shine visible means there is still gel present.\nRepeat steps 2-3 until there is absolutely no residual gel on the sensor cup surface. It is very important that the surface is completely clean.\nPlace the sensors in the disinfectant solution (under sink) for approximately 5 minutes. Ok to put the sensors in at the same time as the cap.\nWhile the sensors are disinfecting, clean the gel applicator and tip.\n\nSquirt excess gel into the garbage can\nRemove the plunger and fill the applicator with water, and squire though the applicator. Repeat a few times\nDisconnect the applicator tip and blow through it\nInspect the tip and make certain that you can see through it with no residual gel.\n\nClean the applicator body\nPut the applicator body and tip back into the organizer on the sink\n\nRemove the sensors from the disinfectant and rinse off disinfectant thoroughly with water. Be sure to put the lid back on the disinfectant.\nSquirt distilled water onto the inside surface of each sensor cup as a final rinse.\nHang the electrodes from the sensor rack to air dry. Make certain that the end of the sensor leads do not hang into the sink."
  },
  {
    "objectID": "psychophysiology_software.html#matlab",
    "href": "psychophysiology_software.html#matlab",
    "title": "18  Psychophysiology Software",
    "section": "18.1 Matlab",
    "text": "18.1 Matlab\nThis document is notes and documentation about Matlab from the server and wiki.\n\n18.1.1 Matlab Support Phone Number\n508-647-7000, Option 5\n\n\n18.1.2 Introductory Matlab readings:\nSee P: Chapter 2: Basic Features\nChapter 3: The Matlab Desktop\nChapter 4: Script M-Files\nChapter 5: Arrays and Array Operations\nChapter 8: Cell Arrays and Structures\nChapter 11: Control Flow\nChapter 12: Functions\nChapter 14: File and Directory Management\nSee Also Matlab Onramp - self-paced online course. To use, create a Mathworks account and check the Campus Software Library page for Matlab for the most recent key.\n\n\n18.1.3 Installing Matlab and updating license and startup files\nFollow these steps to install Matlab (or update to the most current version - an update is a fresh install of a new release)\n\n18.1.3.1 Install Matlab\n\nGet the MathWorks login information from our last pass account. Go to http://www.mathworks.com/\nLogin to the site using our lastpass information\nSelect ‘Support’ menu option (top menu) followed by ‘Download’ sub-option (center panel, left-hand icon)\nThe most recent version will appear as a download link in the center of the screen. Consult with John regarding which version to install. As of 12/2014 we are still installing 2012a. Click the button of the desired release to proceed.\nChoose correct platform (as of 12/2014 32bit to insure compatibility with our I/O), and click. The download will begin (save where prompted, or it will be saved wherever your browser is configured to save files). It is an .exe installation file.\nOnce download is complete, click to begin the installation. Click accept to allow the extractor to run which will begin unzipping the install files. Press Run when prompted to begin the installation.\nChoose ‘Install using the Internet’ and the press ‘Next’. Enter the Mathworks account information when prompted.\nClick ‘Yes’, to accept the terms of the license agreement and then press ‘Next’. Continue to follow the installation prompts.\n\nNote: You can follow the instructions from this point to update the license for any machine which already has Matlab installed\n\nGo to Start Menu -&gt; Program Files -&gt; MATLAB -&gt;  -&gt; Choose “Activate Matlab” (if Matlab is already open after installation, but Activation doesn’t automatically launch, go to the Help menu and select Licensing, then “Activate Software”.)\nSelect “Activate using the Internet”. Enter the Mathworks account information when prompted.\nSelect the correct license which reads: Campus - Academic (rather than Concurrent - Academic). Old way was: TAH Designated Computer. There may be others that look similar (ie TAH Network Concurrent), do not use those. Hit Next\nConfirm the activation settings then hit Activate.\nClose and re-open Matlab to verify activation is complete.\n\n\n\n18.1.3.2 Update Matlab Startup files & Other Setup\nTo allow Matlab to recognize our custom scripts, you need to install our custom startup file. It can be found in P:. Read Matlab Startup Details below for more information about startup and paths work. 1. Download and save this file in the folder at the Matlab root. This folder will be found in the Matlab installation folder in the program files folder. For example, for 2012a installation of matlab, it is found here: Windows: C:Files2012a.m 2. Restart Matlab The only thing done by startup.m is to call P:.m. This latter file contains installation procedures for EEGLab, Physbox, and LedaLab which are handled automatically by Matlab. No commands need to be run to install these plugins/toolboxes and they do not need to be installed manually. To verify, simply call “eeglab” from the Matlab prompt and it should run if all is correct. ARCStartup.m also puts the support folder from CurtinTasks toolbox in path for all machines EXCEPT data collection machines. It checks if a machine is a data collection machine (by name) and excludes them. Data collection still uses study specific /Support in /Programs for each study. NOTE: Computers which cannot connect to the internet (such as the mobile lab at CRU) cannot use this file and will have their own startup file.\n\n\n18.1.3.3 Matlab Startup Details\nWhen Matlab starts, it runs matlabrc.m (located in /toolbox/local from the matlab root). matlabrc.m establishs paths (via pathdef.m) and then calls startup.m. Code in matlabrc.m is executed for all installations of matlab (regardless of user). startup.m provides an opportunity to then do additional custom setup for a specific user. To accomplish this, you could place startup.m in a user folder set up by matlabrc.m but we do not do this. We keep startup.m in /toolbox/local and run the same script for all users.\nStartup only does two things 1. It puts P:in the path. This allows access to genpath_excludem and ARCStartup.m genpath_exclude allows us to not include svn folders for toolboxes under version control in the path. 2. It calls ARCStartup to implement the remaining startup code. This allows us to only edit ACRStartup.m to implement startup changes on all computers at once rather than having to replace startup.m on every computer each time we change something.\nCRU ONLY: startup does one thing 1. It puts C:in the path. This file is located on the server (P:) and called startup_CRU.m and needs to be renamed startup.m on the local CRU computer. This startup file is different because the CRU computer does not have internet access or access to the server. Therefore we reproduce the server infrastructure locally. In other words, study folders (e.g., KAYE2, DOX) live within C: rather than within P:\n\nARCStartup.m does some common tasks across all computers and then some computer specific tasks based on whether the computer is a stimulus control data collection machine vs. all others. For all computers, it puts EEGLab, PhysBox and Ledalab in the path. It adds these to the end of the path (not really that important but maybe a little slower access than earlier folders). Critically, it adds them in a frozen state. This means that matlab will not receive change notification handles if anything changes in these folders. Regardless, Matlab knows if a script/file changes if you edit it in Matlab so this is not a concern if you were to edit a PhysBox function in Matlab. The new function will be recognized as changed. The only time that Matlab would not know a script or other change happens in these folders is if you edit a file outside of matlab (e.g., with Notepad rather than the matlab editor) or if you copy or replace a file through the Explorer. In these rare instances, you should type clear all (or restart matlab) to have it recognize the changes to the scripts/functions.\nThese folders are added as frozen intentionally because there is a performance cost to constantly monitoring for changes in these folders (and also b/c there are a limited number of folders that can be monitored- hence the warnings in the past about running out of change notification handles and we add a LOT of folders for EEGLab, PTB, etc).\nIt should also be noted that the PTB toolbox is NOT added by ARCStartup. This is because PTB adds its folders to the matlab path in pathdef.m when it is installed. Moreover, it wants the folders added to the path in a specific order (bad practice in my opinion) and I didnt want to have to have complicated code to do this in our ARCStartup so I let it do what it wants to do.\nOn all computers other than stimulus control, ARCStartup also adds ‘P:from the CurtinTasks toolbox’. This gives these computers access to the General Matlab and PTB specific code we have written in house. We do NOT want the stimulus control computers to have access to these folders because this code can change and might break a script running in a current (or past) experiment.\nInstead, on stimulus control computers, ARCStartup adds C:to the path. This allows the stimulus control computer to recognize scripts saved in this folder. We then put STUDYNAME.m files in this folder that should be executed before you run PTB for data collection. STUDYNAME.m adds /Programs from the study’s StudyData folder. /Programs contains the code for all the tasks for this study and also a /Support folder that was established at the time the study was initiated. This way, any future changes to /Support in the CurtinTasks toolbox do NOT affect previous studies.\n\n\n\n18.1.4 Matlab Demo Scripts\n\\Matlab\\General\\Demos\n\nDEMO_EMA.m: Creates file for mCore SMS Component to read all scheduled outgoing text messages.\nMakeSound.m: Plays a sound file\nDEMO_ShockValueExtract.m: demo script index and extract particular values from arrays created by shock assess scripts to be analyzed.\nDMDXAggregate.m: Script to loop through individual .dat RT files from DMDX and aggregate into one file\n\n\n\n18.1.5 Matlab Function Library\nSource code for our laboratory’s library of Matlab functions to support general use and PTB is maintained under version control at Sourceforge. This repository also contains PTB code for our specific experimental tasks as well. The repository for source code can be checked out at via username/password at: https://svn.code.sf.net/p/curtintasks/code/trunk A working copy of this repository lives at P:\n\n\n18.1.6 Matlab Reference Card\n\n18.1.6.1 file name and path manipulation\nfileparts()\nfullfile()\n\n\n18.1.6.2 Button dialog for user input\nButtonName = questdlg(‘What is your favorite color?’, … ‘Color Question’, ‘Red’, ‘Green’, ‘Blue’, Green’); switch ButtonName case ‘Red’\n disp('Your favorite color is Red');\ncase ‘Blue’\n disp('Your favorite color is Blue.')\ncase ‘Green’\n  disp('Your favorite color is Green.');\nend #### Use of varargin if ~isempty(varargin)\ntry g = struct(varargin{:});\ncatch error(‘ERROR in pop_CreateAvg: wrong syntax in function arguments’)\nend end\n\n\n18.1.6.3 Cell Arrays\nTestNum = cell(5,1); %allocate a cell array with [] for all entries TestMixed = cell(5,1); %allocate a cell array with [] for all entries TestChar = cell(5,1); %allocate a cell array with [] for all entries %assignment to a cell TestNum{1} = 2; TestNum{2} = 3; TestMixed{4} = 1; TestMixed{5} = ‘John’; TestChar{1} = ‘1234’; TestChar{3} = ‘5678’;\n%indexing into cell Value = TestNum{1} %returns double into value Value = TestNum(1) %returns cell which contains 1 Value = TestMixed{5} %returns ‘John’ as char Value = TestMixed(5) %returns cell\n%use of brackets Value = [TestNum{:}] %returns array of length 2 of double Value = [TestChar{:}] %returns 12345678 as char Value = [TestMixed{:}] %doesnt work (returns char that includes special character for 1 and then John %use of find with numeric entries index = find([TestNum{:}]==2; %result is index 1\n%Deleteing empty cells TestChar(cellfun(‘isempty’,TestChar))= [];\n\n\n\n18.1.7 Fixing Matlab problems\n\n18.1.7.1 Random Number Generators\nMatlab’s random number generators are very misleading. They will all generate the same exact random numbers each time upon restarting matlab. You can get around this by changing the seed before calling this funciton. See matlab help page:http://www.mathworks.com/help/matlab/math/why-do-random-numbers-repeat-after-startup.html\n\n\n18.1.7.2 Path problems\nFor some unknown reason, matlab sometimes (but not always) saves information about files and folders it expects to find on startup in pathdef.m. If you subsequently delete these files or fodlers, Matlab will generate error messages such as: Warning: Name is nonexistent or not a directory: C:Files_0_3_4b. To fix this problem you need to edit the pathdef.m file to delete references to these files and/or folders. Pathdef.m can be found in the toolbox folder (e.g., c:files2010a\n\n\n\n18.1.7.3 Floating point errors\nSee the following Matlab tech note and the follow-up tech notes from this page http://www.mathworks.com/support/solutions/en/data/1-16FOQ/\nWhen you encounter this problem when testing for equality (e.g A == B), try this abs(A-B) &lt; 100*eps\n\n\n18.1.7.4 Filter Error; Boundry Event\n\nI saw your reply on a post in the eeglablist named ‘Filtering trouble’. In my instance, the sampling rate is 500 and the number of frames is 1385355. I tried both 0.1Hz and 0.5Hz for the lower edge of my accepted band when doing a highpass filtering. However, the below error messages happened all the time for 0.1Hz and happened still quite frequently for 0.5Hz. Do you have any suggestion to avoid that kind of error? Thank you very much! Relevant is not the total number of frames, but the number of frames per continuous data epoch/segment (separated by ‘boundary’ events usually inserted by the data acquisition system to mark DC offsets). As far as I remember the EEGLAB built-in “Basic FIR filter” requires the segment to be at least three times longer than the number of filter coefficients. You find ‘boundary’ event indices/latencies fastest from the commandline:\n\n\n\nboundArray = strmatch(‘boundary’, {EEG.event.type}) [EEG.event(boundArray).latency]\n\n\nYou might want to try the “Windowed sinc FIR filter” from the firfilt plugin which does not have this restriction. Reasonable starting values for filter order are 8250 for 0.1 Hz highpass (Hamming window; 0.2 Hz transition band width) or 1650 for\nDear Min,\nyou continuous data is long enough but portions of it are too narrow (portions are defined as the data in between boundary events). Our filters are not optimal for use at these very low frequencies. There has been other messages related to this topic on the list.\nhttp://sccn.ucsd.edu/pipermail/eeglablist/2008/002190.html\nBest regards, A. Delorme \n\n\n18.1.7.5 Out Of Memory Error\nYour problem is likely due to the manner in which the different operating systems handle memory. With Matlab, the largest variable size is determined by the largest contiguous block of free memory. Therefore, even though your Windows machine has 2.5G RAM, the maximum variable size Matlab is able to create and store could be much, much smaller, particularly if you have several processes running in the background.\nYou can check the free contiguous blocks of memory at the Matlab prompt by typing: system_dependent memstats\nThere is a helpful web tutorial dealing with large datasets in Matlab on the Matlab Central File Exchange (http://www.mathworks.com/matlabcentral/fileexchange/loadFile.do?objectId=9060&objectType=file#).\n\n\n18.1.7.6 Generate N random numbers in a one-dimensional vector with values spaced between X1 and X2\nrandom_vector = (x2-x1)*rand(1,N) + x1\nGenerate random data having correlation between column 4 and the other columns. x = randn(30,4); % Uncorrelated data x(:,4) = sum(x,2); % Introduce correlation. [r,p] = corrcoef(x) % Compute sample correlation and p-values. [i,j] = find(p&lt;0.05); % Find significant correlations. [i,j] % Display their (row,col) indices.\nr = 1.0000 -0.3566 0.1929 0.3457 -0.3566 1.0000 -0.1429 0.4461 0.1929 -0.1429 1.0000 0.5183 0.3457 0.4461 0.5183 1.0000\np = 1.0000 0.0531 0.3072 0.0613 0.0531 1.0000 0.4511 0.0135 0.3072 0.4511 1.0000 0.0033 0.0613 0.0135 0.0033 1.0000\nans = 4 2 4 3 2 4 3 4"
  },
  {
    "objectID": "psychophysiology_software.html#neuroscan",
    "href": "psychophysiology_software.html#neuroscan",
    "title": "18  Psychophysiology Software",
    "section": "18.2 Neuroscan",
    "text": "18.2 Neuroscan\n\n18.2.1 Downloading Neuroscan\nScan 4.5 can run on both Windows XP and Windows 7 as long as Scan 4.5.1 is also downloaded, which is a patch that allows Scan 4.5 to run properly. Any Neuroscan software before Scan 4.5 can only run on Windows XP.\nYou may or may not need to upgrade the license on your dongle (‘hardware key’), you won’t know until you install the software and look up license manager (Go to Start and open License Manager). In license manager, ‘Scan 4.3’ should be listed there in order to run Scan 4.5. If you don’t see it there, you should let tech support at Neuroscan know and they will arrange to have it upgraded for you.\n\n\n18.2.2 Installation\nTo install the Scan software, remove your license key before you proceed then uninstall any Scan application that may have been installed then follow the step-by-step instructions below:\n\nDisconnect the amplifier(s).\nDownload 4.5 from the following link: http://dl.dropbox.com/u/11144802/Scan4.5%20Release%20Disk.zip This is a full installation, compressed into a ZIP archive. Download and save, and then copy over to your destination PC. Unzip the file contents into an empty folder, and then run “launch.exe” to begin the installation. Restart the PC when prompted.\nOnce Scan 4.5 is installed, you will need to run the 4.5.1 Hotfix. Download it from: http://dl.dropbox.com/u/11144802/Scan451Hotfix2.exe This is a single EXE file; download and save onto your PC, and then run the EXE file.\nRun the “Amplifier Install” program and select your amplifier (Windows StartInstall).\nConnect your license key and run Edit. If the key is not recognized, do the following: Browse to the Neuroscan folder located in C:Filesand find Scan4.5; run the EXE file (v 7.5.0) in that folder with the dongle disconnected. Afterwards, reconnect the dongle. The 4.5/4.5.1 Release Notes can be downloaded from: http://dl.dropbox.com/u/11144802/Release%20Notes%20451.zip\nAt this point, you can connect your amplifier which should be detected automatically. If the amplifier is not detected automatically, when you try to open Scan 4.5, you receive an error message “Error: Amplifiers not detected.” You should then manually install the amp driver. To do this, simply go to Dev Manager and direct the flagged unidentified USB hardware to upgrade the driver from the following location C:Files (or Program Files(x86)). If you still receive an error message stating that the amplifiers are not detected, you should contact tech support at Neuroscan.\n\n\n\n18.2.3 Neuroscan Setup Files\nNeuroscan requires Setup files (extension .ast) to determine the amplifier settings and recording parameters for your study. Below is an an example setup file for our lab and description of some common parameters. NOTE: The name of the active setup file should display in the lower right corner of the screen next to the workspace name default.aws. If it does not, you may need to set the display resolution above 1280x1024 (per RS at NS Jan 2015) Here is an example neuroscan setup file to record orbicularis, corrugator, and probe: STL_CRG.ast\n\nOnce you download the setup file above open neuroscan acquire and click File &gt; Load Setup… find your file and click Open.\nConfirm or edit your channel assignments by going to Edit &gt; Channel Assignment. The channel assignments table has 3 columns representing the channel number (#), the physical channel on the amplifier (Phys), and the label that is displayed on the screen for that channel (Label). The example file above has the following channel assignments:\n\n\nOrbicularis: # = 1; Phys = BP2; Label = ORB\nCorrugator: # = 2; Phys = BP3; Label = CRG\nProbe: # = 3; Phys = HL1; Label = PRB\n\n\nNow check your overall parameters by going to Edit &gt; Overall Parameters. Below are listed common parameters we use for data collection:\n\n\nStartup:\nSingle Window Display No 1: Check Enable\nNegative: Check Up\nAmplifiers (SN2):\nAcquisition:\nA/D Rate = 2500\nNumber of Channels = 3 (Note: modify this to match the number of channels you are actually collecting.)\nAcquisition Type = Continuous\nAC/DC = Check DC\nAmplifier Settings\nLow pass = 500Hz (See pt 4 below)\nHigh pass = DC\nClick Apply To All Selected Channels (First, Click Select All)\nNotch\nFrequency = Off\nTriggers\nCheck External.\nHold value = 0 (Note: This must match your hold value designated in the header of your stimulus presentation program. Some programs in our lab have used 255, so confirm that this matches your DMDX or Matlab program).\n\n\nMuch of our filtering of data is done off-line in post-collection data processing. Historically, high pass hardware filters were necessary during data collection because older amplifiers (e.g., 8, 12, 16 bit) would saturate causing problems with data recording. Current amplifiers (e.g., 32 bit) do not appear to have this problem making hardware high pass filters unnecessary. Our lab’s current procedure is to collect all channels with the high pass filter set to “DC” and the low pass filter set to “500”. This DC-500 hz hardware filtering gives us total flexibility to use what offline digital filter we deem necessary in later data processing. Given this practice, we should continue to monitor data as it is being collected to ensure that channels with large responses (e.g., ORB for startle) do not saturate"
  },
  {
    "objectID": "psychophysiology_software.html#curry",
    "href": "psychophysiology_software.html#curry",
    "title": "18  Psychophysiology Software",
    "section": "18.3 Curry",
    "text": "18.3 Curry\n\n18.3.1 Installing Curry\n\nInstaller package comes with an installer CD, tutorial CD, and a USB dongle.\nThe Dell Latitude laptop being uses for the mobile lab does not have an optical drive. Therefore, the contents of the installer CD were copied to P://Private/Documentation/Neuroscan/Curry/Installer Disk\nRun setup.exe from the installer disk folder.\nWhen prompted to choose which components to install, select: EEG acquisition, Core Files, Dongle Drivers, and Amplifier Drivers.\n\n\nDo NOT install: EEG/MEG analysis, Head models, Example Data\n\n\nWhen the installer gets to the Amplifier Driver Installation, an onscreen prompt tells you to follow the onscreen directions.\n\n\nA secondary (device driver) installation window opens\nGive windows security approval to allow Compumedics to install the drivers by clicking the Install button.\nClick finish when the wizard indicates it is finished. It now returns to the main installer.\n\n\nAt the end of installation the finish window reminds you that a hardware lock “dongle” is required to run the software.\nGo ahead and start the Curry 7 acquisition\nA license information window will come up saying “dongle not found”\n\n\nPlug in the dongle and hit refresh. NOTE: The dongle must be plugged in at all times for the software to run. Just plug it in and leave it alone.\nClose the dongle window.\n\n\nGo to the start menu and run Curry 7 acquisition from the Start or Programs menu.\n\n\n\n18.3.2 Updating after First Install\n\nAt first launch, you will be prompted to do an online update; hit yes\nYou will receive another window that says you have to send a notification email to Neuroscan\n\n\nIf you don’t have an email editor like Outlook installed (which you shouldn’t) click the button that says “no email”\nA text box will pop up, and you will be instructed to copy and paste this into an email which you can do via Wiscmail.\n\n\nAn executable update will available. Click to download, than click to run\n\n\nNote you must close Curry first\n\n\nWhen that is finished, start the Neuroimaging suite again, and you will have been updated from 7.0.6 to 7.0.10\nYou will now have another email which you have to send. Follow the procedure above.\n\n\n\n18.3.3 Curry Configuration Files\nCurry requires Configuration files to determine the amplifier settings and recording parameters for your study. There are both Amplifier Configuration files (.xml extension) and Global Parameters files (.cfg). These are roughly the equivalent of the Set-Up (.ast) files from SCAN. Below is an an example setup file for our lab and description of some common parameters.\n\n18.3.3.1 Amplifier Configuration\n\nIn general it is recommended that you start with an existing configuration file and modify it rather than starting from scratch. See notes below for more.\nAmplifier: Grael EEG (demo below is for Grael)\nSampling rate = 2048 Hz (required for triggering, see below)\nMode: DC\nLow Pass: 819 Hz (default - unclear if this can/should be modified to 500Hz)\nClick on each site (or hold Ctrl for multiple sites) and select on/off the sites you will collect.\nFor bipolar channels the Electrode No is the number and you can enter a Name (e.g, “ORB”)\n\n\n\n18.3.3.2 Sensor Placement\n\nCan use one of the defaults or create a new montage that is just for bipolar channels.\nFor bipolar channels the Active should be the channel number and Ref column should remain empty.\n\n\n\n18.3.3.3 Special limitations with the Grael trigger module.\nIf you are using the trigger unit with the Grael PSG or EEG amplifier, you should be aware of the following limitations:\n\nTriggers are only registered when acquiring data with the fastest sampling rate (2048Hz).\nOnly stimulus events from 1-64 are registered; no response events are recognized.\nThe maximum trigger frequency is 40Hz.\nThe “Record Event Duration” option does not work with Grael.\n\n\n\n\n18.3.4 Global Parameters\n\n18.3.4.1 Amplifier Controls:\n\nSampling rate must be 2048Hz for triggers to register.\nLoad your configuration file.\nSet the path you want to save data for your study. Then click File-&gt;Parameters-&gt;Save Global Parameters.\nTrigger settings:\nSelect Neuroscan Stim2\nStimulus should be unchecked from Invert and Response should be checked for Invert (although we’re not actually collecting Invert).\n\n\n\n18.3.4.2 Filter Parameters:\n\nRaw: Raw should be selected. The tab that is selected is the current tab that is viewed during data collection. It is very important to always select RAW (it will also be displayed F-SET: Raw in the top left corner of the recording window).\n\nBaseline checked\nAll other parameters will be blocked out and unable to modify.\n\nOptions MGFP unchecked (in order to have access to uncheck this you must be acquiring data) . MGFP is the mean global field power.\n\n\n\n\n18.3.5 Notes\n\nNOTES: The computer can not be connected to VPN and connect to the amplifer at the same time. This is likely because the way the amplifier is detected over the network and the changing ip address used with each user’s vpn account.\nWe identified two software bugs on Curry. First when creating a new configuration from scratch the default setting is to set the trigger channel to off (0 sampling rate). This does not appear to be modifiable in the GUI. Therefore you need to start with an existing/working or the default configuration file for triggers to appear - and modify that file to your specs and save as new config file. Second, bipolar channels do not display impedances for both plus and minux channel separately.\nBoth of these bugs are fixed in a custom patch sent to us from Curry tech support. Hotfix is saved on the server: P:and Peripherals701029Hotfix.exe\nSampling rate must be set at 2048Hz for triggers to register in Grael EEG.\nBipolar channels are optically isolated from each other (per Ronnie email 2016_0728) and therefore it is safe to send audio/probe channel into bipolar channel while recording. Must be attenuated within range (&lt;600uV or +-300uV)."
  },
  {
    "objectID": "psychophysiology_software.html#physbox",
    "href": "psychophysiology_software.html#physbox",
    "title": "18  Psychophysiology Software",
    "section": "18.4 Physbox",
    "text": "18.4 Physbox\nSee documentation at https://arc.psych.wisc.edu/physbox/"
  }
]